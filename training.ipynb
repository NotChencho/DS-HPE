{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
   "execution_count": null,
   "id": "83b87cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
=======
=======
>>>>>>> Stashed changes
   "execution_count": 84,
   "id": "2228800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f4e187a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "data_path = r\"C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\final_dataset.csv\"\n",
    "data_target = r\"C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\data\\interm\\data_to_train_meantime.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dc1dc12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaime\\AppData\\Local\\Temp\\ipykernel_25576\\3487717889.py:3: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n"
     ]
    }
   ],
   "source": [
    "# LOAD THE ESSENTIALS\n",
    "\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ea940766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>group_id</th>\n",
       "      <th>group_major</th>\n",
       "      <th>submit_time</th>\n",
       "      <th>time_limit_cat</th>\n",
       "      <th>time_limit_scaled</th>\n",
       "      <th>num_nodes_req</th>\n",
       "      <th>has_req_nodes</th>\n",
       "      <th>num_cores_req</th>\n",
       "      <th>cores_per_task</th>\n",
       "      <th>num_tasks_final</th>\n",
       "      <th>num_gpus_req</th>\n",
       "      <th>mem_req</th>\n",
       "      <th>has_req_threads_per_core</th>\n",
       "      <th>is_shared_job</th>\n",
       "      <th>num_tasks_missing_or_inconsistent</th>\n",
       "      <th>partition_final</th>\n",
       "      <th>qos_final</th>\n",
       "      <th>dow_0</th>\n",
       "      <th>dow_1</th>\n",
       "      <th>dow_2</th>\n",
       "      <th>dow_3</th>\n",
       "      <th>dow_4</th>\n",
       "      <th>dow_5</th>\n",
       "      <th>dow_6</th>\n",
       "      <th>dom_1</th>\n",
       "      <th>dom_2</th>\n",
       "      <th>dom_3</th>\n",
       "      <th>dom_4</th>\n",
       "      <th>dom_5</th>\n",
       "      <th>dom_6</th>\n",
       "      <th>dom_7</th>\n",
       "      <th>dom_8</th>\n",
       "      <th>dom_9</th>\n",
       "      <th>dom_10</th>\n",
       "      <th>dom_11</th>\n",
       "      <th>dom_12</th>\n",
       "      <th>dom_13</th>\n",
       "      <th>dom_14</th>\n",
       "      <th>dom_15</th>\n",
       "      <th>dom_16</th>\n",
       "      <th>dom_17</th>\n",
       "      <th>dom_18</th>\n",
       "      <th>dom_19</th>\n",
       "      <th>dom_20</th>\n",
       "      <th>dom_21</th>\n",
       "      <th>dom_22</th>\n",
       "      <th>dom_23</th>\n",
       "      <th>dom_24</th>\n",
       "      <th>dom_25</th>\n",
       "      <th>dom_26</th>\n",
       "      <th>dom_27</th>\n",
       "      <th>dom_28</th>\n",
       "      <th>dom_29</th>\n",
       "      <th>dom_30</th>\n",
       "      <th>dom_31</th>\n",
       "      <th>hour_0</th>\n",
       "      <th>hour_1</th>\n",
       "      <th>hour_2</th>\n",
       "      <th>hour_3</th>\n",
       "      <th>hour_4</th>\n",
       "      <th>hour_5</th>\n",
       "      <th>hour_6</th>\n",
       "      <th>hour_7</th>\n",
       "      <th>hour_8</th>\n",
       "      <th>hour_9</th>\n",
       "      <th>hour_10</th>\n",
       "      <th>hour_11</th>\n",
       "      <th>hour_12</th>\n",
       "      <th>hour_13</th>\n",
       "      <th>hour_14</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>node_power_consumption</th>\n",
       "      <th>mem_power_consumption</th>\n",
       "      <th>cpu_power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25200</td>\n",
       "      <td>main</td>\n",
       "      <td>2020-05-31 22:09:29+00:00</td>\n",
       "      <td>medium (1–5h)</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[7970 8450 8460 8470 7440 8470 8460 8470 7910 ...</td>\n",
       "      <td>[418 724 724 678 556 654 606 600 600 488 606 4...</td>\n",
       "      <td>[ 948 1628 1650 1544 1260 1532 1418 1700 1710 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25200</td>\n",
       "      <td>main</td>\n",
       "      <td>2020-05-31 22:22:08+00:00</td>\n",
       "      <td>medium (1–5h)</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[7970 8430 7940 8480 7460 8490 6890 8480 8480 ...</td>\n",
       "      <td>[720 738 736 614 720 642 632 524 598 628 616 5...</td>\n",
       "      <td>[1640 1604 1592 1364 1532 1508 1528 1476 1674 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>main</td>\n",
       "      <td>2020-05-31 22:41:38+00:00</td>\n",
       "      <td>medium (1–5h)</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[7950 7970 8500 8480 8470 6900 8460 8450 8470 ...</td>\n",
       "      <td>[672 720 716 630 674 474 644 606 602 564 650 5...</td>\n",
       "      <td>[1654 1600 1606 1438 1506 1108 1496 1670 1680 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>25200</td>\n",
       "      <td>main</td>\n",
       "      <td>2020-05-31 23:26:23+00:00</td>\n",
       "      <td>short (&lt;1h)</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[860 860 860 860 860 860 860 860 860 860 860 8...</td>\n",
       "      <td>[38 40 46 44 48 40 44 46 42 40 40 40 38 46 44 ...</td>\n",
       "      <td>[108 182 178 182 190 174 188 186 190 176 176 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>25200</td>\n",
       "      <td>main</td>\n",
       "      <td>2020-05-31 23:08:01+00:00</td>\n",
       "      <td>short (&lt;1h)</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[860 860 860 860 860 860 860 860 860 860 860 8...</td>\n",
       "      <td>[36 44 42 42 44 40 44 42 50 42 42 46 48 42 44 ...</td>\n",
       "      <td>[ 82 182 178 180 170 168 168 192 196 166 196 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  group_id group_major                submit_time time_limit_cat  \\\n",
       "0           0     25200        main  2020-05-31 22:09:29+00:00  medium (1–5h)   \n",
       "1           1     25200        main  2020-05-31 22:22:08+00:00  medium (1–5h)   \n",
       "2           2     25200        main  2020-05-31 22:41:38+00:00  medium (1–5h)   \n",
       "3           3     25200        main  2020-05-31 23:26:23+00:00    short (<1h)   \n",
       "4           4     25200        main  2020-05-31 23:08:01+00:00    short (<1h)   \n",
       "\n",
       "   time_limit_scaled  num_nodes_req  has_req_nodes  num_cores_req  \\\n",
       "0          -0.007838             16              0            256   \n",
       "1          -0.007838             16              0            256   \n",
       "2          -0.007838             16              0            256   \n",
       "3          -1.243395              1              0             32   \n",
       "4          -1.243395              1              0             32   \n",
       "\n",
       "   cores_per_task  num_tasks_final  num_gpus_req  mem_req  \\\n",
       "0               4               64            64      475   \n",
       "1               4               64            64      475   \n",
       "2               4               64            64      475   \n",
       "3              32                0             4       59   \n",
       "4              32                0             4       59   \n",
       "\n",
       "   has_req_threads_per_core  is_shared_job  num_tasks_missing_or_inconsistent  \\\n",
       "0                         0              0                              False   \n",
       "1                         0              0                              False   \n",
       "2                         0              0                              False   \n",
       "3                         0              1                               True   \n",
       "4                         0              1                               True   \n",
       "\n",
       "   partition_final qos_final  dow_0  dow_1  dow_2  dow_3  dow_4  dow_5  dow_6  \\\n",
       "0                1         1  False  False  False  False  False  False   True   \n",
       "1                1         1  False  False  False  False  False  False   True   \n",
       "2                1         1  False  False  False  False  False  False   True   \n",
       "3                1         1  False  False  False  False  False  False   True   \n",
       "4                1         1  False  False  False  False  False  False   True   \n",
       "\n",
       "   dom_1  dom_2  dom_3  dom_4  dom_5  dom_6  dom_7  dom_8  dom_9  dom_10  \\\n",
       "0  False  False  False  False  False  False  False  False  False   False   \n",
       "1  False  False  False  False  False  False  False  False  False   False   \n",
       "2  False  False  False  False  False  False  False  False  False   False   \n",
       "3  False  False  False  False  False  False  False  False  False   False   \n",
       "4  False  False  False  False  False  False  False  False  False   False   \n",
       "\n",
       "   dom_11  dom_12  dom_13  dom_14  dom_15  dom_16  dom_17  dom_18  dom_19  \\\n",
       "0   False   False   False   False   False   False   False   False   False   \n",
       "1   False   False   False   False   False   False   False   False   False   \n",
       "2   False   False   False   False   False   False   False   False   False   \n",
       "3   False   False   False   False   False   False   False   False   False   \n",
       "4   False   False   False   False   False   False   False   False   False   \n",
       "\n",
       "   dom_20  dom_21  dom_22  dom_23  dom_24  dom_25  dom_26  dom_27  dom_28  \\\n",
       "0   False   False   False   False   False   False   False   False   False   \n",
       "1   False   False   False   False   False   False   False   False   False   \n",
       "2   False   False   False   False   False   False   False   False   False   \n",
       "3   False   False   False   False   False   False   False   False   False   \n",
       "4   False   False   False   False   False   False   False   False   False   \n",
       "\n",
       "   dom_29  dom_30  dom_31  hour_0  hour_1  hour_2  hour_3  hour_4  hour_5  \\\n",
       "0   False   False    True   False   False   False   False   False   False   \n",
       "1   False   False    True   False   False   False   False   False   False   \n",
       "2   False   False    True   False   False   False   False   False   False   \n",
       "3   False   False    True   False   False   False   False   False   False   \n",
       "4   False   False    True   False   False   False   False   False   False   \n",
       "\n",
       "   hour_6  hour_7  hour_8  hour_9  hour_10  hour_11  hour_12  hour_13  \\\n",
       "0   False   False   False   False    False    False    False    False   \n",
       "1   False   False   False   False    False    False    False    False   \n",
       "2   False   False   False   False    False    False    False    False   \n",
       "3   False   False   False   False    False    False    False    False   \n",
       "4   False   False   False   False    False    False    False    False   \n",
       "\n",
       "   hour_14  hour_15  hour_16  hour_17  hour_18  hour_19  hour_20  hour_21  \\\n",
       "0    False    False    False    False    False    False    False    False   \n",
       "1    False    False    False    False    False    False    False    False   \n",
       "2    False    False    False    False    False    False    False    False   \n",
       "3    False    False    False    False    False    False    False    False   \n",
       "4    False    False    False    False    False    False    False    False   \n",
       "\n",
       "   hour_22  hour_23                             node_power_consumption  \\\n",
       "0     True    False  [7970 8450 8460 8470 7440 8470 8460 8470 7910 ...   \n",
       "1     True    False  [7970 8430 7940 8480 7460 8490 6890 8480 8480 ...   \n",
       "2     True    False  [7950 7970 8500 8480 8470 6900 8460 8450 8470 ...   \n",
       "3    False     True  [860 860 860 860 860 860 860 860 860 860 860 8...   \n",
       "4    False     True  [860 860 860 860 860 860 860 860 860 860 860 8...   \n",
       "\n",
       "                               mem_power_consumption  \\\n",
       "0  [418 724 724 678 556 654 606 600 600 488 606 4...   \n",
       "1  [720 738 736 614 720 642 632 524 598 628 616 5...   \n",
       "2  [672 720 716 630 674 474 644 606 602 564 650 5...   \n",
       "3  [38 40 46 44 48 40 44 46 42 40 40 40 38 46 44 ...   \n",
       "4  [36 44 42 42 44 40 44 42 50 42 42 46 48 42 44 ...   \n",
       "\n",
       "                               cpu_power_consumption  \n",
       "0  [ 948 1628 1650 1544 1260 1532 1418 1700 1710 ...  \n",
       "1  [1640 1604 1592 1364 1532 1508 1528 1476 1674 ...  \n",
       "2  [1654 1600 1606 1438 1506 1108 1496 1670 1680 ...  \n",
       "3  [108 182 178 182 190 174 188 186 190 176 176 1...  \n",
       "4  [ 82 182 178 180 170 168 168 192 196 166 196 1...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a0917416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaime\\AppData\\Local\\Temp\\ipykernel_25576\\2317222573.py:2: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_check = pd.read_csv(data_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns in CSV file:\n",
      "['Unnamed: 0', 'group_id', 'group_major', 'submit_time', 'time_limit_cat', 'time_limit_scaled', 'num_nodes_req', 'has_req_nodes', 'num_cores_req', 'cores_per_task', 'num_tasks_final', 'num_gpus_req', 'mem_req', 'has_req_threads_per_core', 'is_shared_job', 'num_tasks_missing_or_inconsistent', 'partition_final', 'qos_final', 'dow_0', 'dow_1', 'dow_2', 'dow_3', 'dow_4', 'dow_5', 'dow_6', 'dom_1', 'dom_2', 'dom_3', 'dom_4', 'dom_5', 'dom_6', 'dom_7', 'dom_8', 'dom_9', 'dom_10', 'dom_11', 'dom_12', 'dom_13', 'dom_14', 'dom_15', 'dom_16', 'dom_17', 'dom_18', 'dom_19', 'dom_20', 'dom_21', 'dom_22', 'dom_23', 'dom_24', 'dom_25', 'dom_26', 'dom_27', 'dom_28', 'dom_29', 'dom_30', 'dom_31', 'hour_0', 'hour_1', 'hour_2', 'hour_3', 'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10', 'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16', 'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22', 'hour_23', 'node_power_consumption', 'mem_power_consumption', 'cpu_power_consumption']\n",
      "\n",
      "Total columns: 83\n",
      "\n",
      "Power-related columns: ['node_power_consumption', 'mem_power_consumption', 'cpu_power_consumption']\n"
     ]
    }
   ],
   "source": [
    "# Check ALL columns in the FRESH loaded dataframe\n",
    "df_check = pd.read_csv(data_path)\n",
    "print(\"All columns in CSV file:\")\n",
    "print(df_check.columns.tolist())\n",
    "print(f\"\\nTotal columns: {len(df_check.columns)}\")\n",
    "\n",
    "# Check for power consumption columns\n",
    "power_cols = [col for col in df_check.columns if 'power' in col.lower()]\n",
    "print(f\"\\nPower-related columns: {power_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ff6621c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unwanted columns but KEEP the power consumption columns for targets\n",
    "df = df.drop(columns=[\"Unnamed: 0\",\"qos_final\",\"submit_time\", \"time_limit_cat\", \"group_major\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f8e93e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>time_limit_scaled</th>\n",
       "      <th>num_nodes_req</th>\n",
       "      <th>has_req_nodes</th>\n",
       "      <th>num_cores_req</th>\n",
       "      <th>cores_per_task</th>\n",
       "      <th>num_tasks_final</th>\n",
       "      <th>num_gpus_req</th>\n",
       "      <th>mem_req</th>\n",
       "      <th>has_req_threads_per_core</th>\n",
       "      <th>is_shared_job</th>\n",
       "      <th>num_tasks_missing_or_inconsistent</th>\n",
       "      <th>partition_final</th>\n",
       "      <th>dow_0</th>\n",
       "      <th>dow_1</th>\n",
       "      <th>dow_2</th>\n",
       "      <th>dow_3</th>\n",
       "      <th>dow_4</th>\n",
       "      <th>dow_5</th>\n",
       "      <th>dow_6</th>\n",
       "      <th>dom_1</th>\n",
       "      <th>dom_2</th>\n",
       "      <th>dom_3</th>\n",
       "      <th>dom_4</th>\n",
       "      <th>dom_5</th>\n",
       "      <th>dom_6</th>\n",
       "      <th>dom_7</th>\n",
       "      <th>dom_8</th>\n",
       "      <th>dom_9</th>\n",
       "      <th>dom_10</th>\n",
       "      <th>dom_11</th>\n",
       "      <th>dom_12</th>\n",
       "      <th>dom_13</th>\n",
       "      <th>dom_14</th>\n",
       "      <th>dom_15</th>\n",
       "      <th>dom_16</th>\n",
       "      <th>dom_17</th>\n",
       "      <th>dom_18</th>\n",
       "      <th>dom_19</th>\n",
       "      <th>dom_20</th>\n",
       "      <th>dom_21</th>\n",
       "      <th>dom_22</th>\n",
       "      <th>dom_23</th>\n",
       "      <th>dom_24</th>\n",
       "      <th>dom_25</th>\n",
       "      <th>dom_26</th>\n",
       "      <th>dom_27</th>\n",
       "      <th>dom_28</th>\n",
       "      <th>dom_29</th>\n",
       "      <th>dom_30</th>\n",
       "      <th>dom_31</th>\n",
       "      <th>hour_0</th>\n",
       "      <th>hour_1</th>\n",
       "      <th>hour_2</th>\n",
       "      <th>hour_3</th>\n",
       "      <th>hour_4</th>\n",
       "      <th>hour_5</th>\n",
       "      <th>hour_6</th>\n",
       "      <th>hour_7</th>\n",
       "      <th>hour_8</th>\n",
       "      <th>hour_9</th>\n",
       "      <th>hour_10</th>\n",
       "      <th>hour_11</th>\n",
       "      <th>hour_12</th>\n",
       "      <th>hour_13</th>\n",
       "      <th>hour_14</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>node_power_consumption</th>\n",
       "      <th>mem_power_consumption</th>\n",
       "      <th>cpu_power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25200</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[7970 8450 8460 8470 7440 8470 8460 8470 7910 ...</td>\n",
       "      <td>[418 724 724 678 556 654 606 600 600 488 606 4...</td>\n",
       "      <td>[ 948 1628 1650 1544 1260 1532 1418 1700 1710 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25200</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[7970 8430 7940 8480 7460 8490 6890 8480 8480 ...</td>\n",
       "      <td>[720 738 736 614 720 642 632 524 598 628 616 5...</td>\n",
       "      <td>[1640 1604 1592 1364 1532 1508 1528 1476 1674 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25200</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[7950 7970 8500 8480 8470 6900 8460 8450 8470 ...</td>\n",
       "      <td>[672 720 716 630 674 474 644 606 602 564 650 5...</td>\n",
       "      <td>[1654 1600 1606 1438 1506 1108 1496 1670 1680 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25200</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[860 860 860 860 860 860 860 860 860 860 860 8...</td>\n",
       "      <td>[38 40 46 44 48 40 44 46 42 40 40 40 38 46 44 ...</td>\n",
       "      <td>[108 182 178 182 190 174 188 186 190 176 176 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25200</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[860 860 860 860 860 860 860 860 860 860 860 8...</td>\n",
       "      <td>[36 44 42 42 44 40 44 42 50 42 42 46 48 42 44 ...</td>\n",
       "      <td>[ 82 182 178 180 170 168 168 192 196 166 196 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231233</th>\n",
       "      <td>25200</td>\n",
       "      <td>0.944404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[920]</td>\n",
       "      <td>[36]</td>\n",
       "      <td>[90]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231234</th>\n",
       "      <td>25200</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[870 860 860 860 860 870 860 870 860 860 860 8...</td>\n",
       "      <td>[44 36 36 36 36 36 36 36 52 36 36 36 36 36 36 ...</td>\n",
       "      <td>[ 96  92 100  90  92  94  98  94  96  90  90  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231235</th>\n",
       "      <td>25200</td>\n",
       "      <td>0.386115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 620  620  610  630  630  630  620  620  630 ...</td>\n",
       "      <td>[38 40 38 38 38 42 38 38 40 38 38 38 38 38 40 ...</td>\n",
       "      <td>[282 202 246 234 274 288 274 288 250 252 284 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231236</th>\n",
       "      <td>25200</td>\n",
       "      <td>0.944404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[860]</td>\n",
       "      <td>[36]</td>\n",
       "      <td>[46]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231237</th>\n",
       "      <td>25200</td>\n",
       "      <td>0.944404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[900]</td>\n",
       "      <td>[36]</td>\n",
       "      <td>[58]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231238 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        group_id  time_limit_scaled  num_nodes_req  has_req_nodes  \\\n",
       "0          25200          -0.007838             16              0   \n",
       "1          25200          -0.007838             16              0   \n",
       "2          25200          -0.007838             16              0   \n",
       "3          25200          -1.243395              1              0   \n",
       "4          25200          -1.243395              1              0   \n",
       "...          ...                ...            ...            ...   \n",
       "231233     25200           0.944404              1              0   \n",
       "231234     25200          -1.243395              1              1   \n",
       "231235     25200           0.386115              1              0   \n",
       "231236     25200           0.944404              1              0   \n",
       "231237     25200           0.944404              1              0   \n",
       "\n",
       "        num_cores_req  cores_per_task  num_tasks_final  num_gpus_req  mem_req  \\\n",
       "0                 256               4               64            64      475   \n",
       "1                 256               4               64            64      475   \n",
       "2                 256               4               64            64      475   \n",
       "3                  32              32                0             4       59   \n",
       "4                  32              32                0             4       59   \n",
       "...               ...             ...              ...           ...      ...   \n",
       "231233            128              32                4             4      237   \n",
       "231234              4               1                4             4        7   \n",
       "231235            128              16                8             4      234   \n",
       "231236            128              32                4             4      237   \n",
       "231237            128              32                4             4      237   \n",
       "\n",
       "        has_req_threads_per_core  is_shared_job  \\\n",
       "0                              0              0   \n",
       "1                              0              0   \n",
       "2                              0              0   \n",
       "3                              0              1   \n",
       "4                              0              1   \n",
       "...                          ...            ...   \n",
       "231233                         0              1   \n",
       "231234                         0              0   \n",
       "231235                         0              1   \n",
       "231236                         0              1   \n",
       "231237                         0              1   \n",
       "\n",
       "        num_tasks_missing_or_inconsistent  partition_final  dow_0  dow_1  \\\n",
       "0                                       0                1      0      0   \n",
       "1                                       0                1      0      0   \n",
       "2                                       0                1      0      0   \n",
       "3                                       1                1      0      0   \n",
       "4                                       1                1      0      0   \n",
       "...                                   ...              ...    ...    ...   \n",
       "231233                                  0                1      0      0   \n",
       "231234                                  0                1      0      0   \n",
       "231235                                  0                1      0      0   \n",
       "231236                                  0                1      0      0   \n",
       "231237                                  0                1      0      0   \n",
       "\n",
       "        dow_2  dow_3  dow_4  dow_5  dow_6  dom_1  dom_2  dom_3  dom_4  dom_5  \\\n",
       "0           0      0      0      0      1      0      0      0      0      0   \n",
       "1           0      0      0      0      1      0      0      0      0      0   \n",
       "2           0      0      0      0      1      0      0      0      0      0   \n",
       "3           0      0      0      0      1      0      0      0      0      0   \n",
       "4           0      0      0      0      1      0      0      0      0      0   \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "231233      1      0      0      0      0      0      0      0      0      0   \n",
       "231234      1      0      0      0      0      0      0      0      0      0   \n",
       "231235      1      0      0      0      0      0      0      0      0      0   \n",
       "231236      1      0      0      0      0      0      0      0      0      0   \n",
       "231237      1      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "        dom_6  dom_7  dom_8  dom_9  dom_10  dom_11  dom_12  dom_13  dom_14  \\\n",
       "0           0      0      0      0       0       0       0       0       0   \n",
       "1           0      0      0      0       0       0       0       0       0   \n",
       "2           0      0      0      0       0       0       0       0       0   \n",
       "3           0      0      0      0       0       0       0       0       0   \n",
       "4           0      0      0      0       0       0       0       0       0   \n",
       "...       ...    ...    ...    ...     ...     ...     ...     ...     ...   \n",
       "231233      0      1      0      0       0       0       0       0       0   \n",
       "231234      0      1      0      0       0       0       0       0       0   \n",
       "231235      0      1      0      0       0       0       0       0       0   \n",
       "231236      0      1      0      0       0       0       0       0       0   \n",
       "231237      0      1      0      0       0       0       0       0       0   \n",
       "\n",
       "        dom_15  dom_16  dom_17  dom_18  dom_19  dom_20  dom_21  dom_22  \\\n",
       "0            0       0       0       0       0       0       0       0   \n",
       "1            0       0       0       0       0       0       0       0   \n",
       "2            0       0       0       0       0       0       0       0   \n",
       "3            0       0       0       0       0       0       0       0   \n",
       "4            0       0       0       0       0       0       0       0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "231233       0       0       0       0       0       0       0       0   \n",
       "231234       0       0       0       0       0       0       0       0   \n",
       "231235       0       0       0       0       0       0       0       0   \n",
       "231236       0       0       0       0       0       0       0       0   \n",
       "231237       0       0       0       0       0       0       0       0   \n",
       "\n",
       "        dom_23  dom_24  dom_25  dom_26  dom_27  dom_28  dom_29  dom_30  \\\n",
       "0            0       0       0       0       0       0       0       0   \n",
       "1            0       0       0       0       0       0       0       0   \n",
       "2            0       0       0       0       0       0       0       0   \n",
       "3            0       0       0       0       0       0       0       0   \n",
       "4            0       0       0       0       0       0       0       0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "231233       0       0       0       0       0       0       0       0   \n",
       "231234       0       0       0       0       0       0       0       0   \n",
       "231235       0       0       0       0       0       0       0       0   \n",
       "231236       0       0       0       0       0       0       0       0   \n",
       "231237       0       0       0       0       0       0       0       0   \n",
       "\n",
       "        dom_31  hour_0  hour_1  hour_2  hour_3  hour_4  hour_5  hour_6  \\\n",
       "0            1       0       0       0       0       0       0       0   \n",
       "1            1       0       0       0       0       0       0       0   \n",
       "2            1       0       0       0       0       0       0       0   \n",
       "3            1       0       0       0       0       0       0       0   \n",
       "4            1       0       0       0       0       0       0       0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "231233       0       0       0       0       0       0       1       0   \n",
       "231234       0       0       0       0       0       0       0       0   \n",
       "231235       0       0       0       0       0       0       0       0   \n",
       "231236       0       0       0       0       0       0       0       1   \n",
       "231237       0       0       1       0       0       0       0       0   \n",
       "\n",
       "        hour_7  hour_8  hour_9  hour_10  hour_11  hour_12  hour_13  hour_14  \\\n",
       "0            0       0       0        0        0        0        0        0   \n",
       "1            0       0       0        0        0        0        0        0   \n",
       "2            0       0       0        0        0        0        0        0   \n",
       "3            0       0       0        0        0        0        0        0   \n",
       "4            0       0       0        0        0        0        0        0   \n",
       "...        ...     ...     ...      ...      ...      ...      ...      ...   \n",
       "231233       0       0       0        0        0        0        0        0   \n",
       "231234       1       0       0        0        0        0        0        0   \n",
       "231235       0       0       1        0        0        0        0        0   \n",
       "231236       0       0       0        0        0        0        0        0   \n",
       "231237       0       0       0        0        0        0        0        0   \n",
       "\n",
       "        hour_15  hour_16  hour_17  hour_18  hour_19  hour_20  hour_21  \\\n",
       "0             0        0        0        0        0        0        0   \n",
       "1             0        0        0        0        0        0        0   \n",
       "2             0        0        0        0        0        0        0   \n",
       "3             0        0        0        0        0        0        0   \n",
       "4             0        0        0        0        0        0        0   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "231233        0        0        0        0        0        0        0   \n",
       "231234        0        0        0        0        0        0        0   \n",
       "231235        0        0        0        0        0        0        0   \n",
       "231236        0        0        0        0        0        0        0   \n",
       "231237        0        0        0        0        0        0        0   \n",
       "\n",
       "        hour_22  hour_23                             node_power_consumption  \\\n",
       "0             1        0  [7970 8450 8460 8470 7440 8470 8460 8470 7910 ...   \n",
       "1             1        0  [7970 8430 7940 8480 7460 8490 6890 8480 8480 ...   \n",
       "2             1        0  [7950 7970 8500 8480 8470 6900 8460 8450 8470 ...   \n",
       "3             0        1  [860 860 860 860 860 860 860 860 860 860 860 8...   \n",
       "4             0        1  [860 860 860 860 860 860 860 860 860 860 860 8...   \n",
       "...         ...      ...                                                ...   \n",
       "231233        0        0                                              [920]   \n",
       "231234        0        0  [870 860 860 860 860 870 860 870 860 860 860 8...   \n",
       "231235        0        0  [ 620  620  610  630  630  630  620  620  630 ...   \n",
       "231236        0        0                                              [860]   \n",
       "231237        0        0                                              [900]   \n",
       "\n",
       "                                    mem_power_consumption  \\\n",
       "0       [418 724 724 678 556 654 606 600 600 488 606 4...   \n",
       "1       [720 738 736 614 720 642 632 524 598 628 616 5...   \n",
       "2       [672 720 716 630 674 474 644 606 602 564 650 5...   \n",
       "3       [38 40 46 44 48 40 44 46 42 40 40 40 38 46 44 ...   \n",
       "4       [36 44 42 42 44 40 44 42 50 42 42 46 48 42 44 ...   \n",
       "...                                                   ...   \n",
       "231233                                               [36]   \n",
       "231234  [44 36 36 36 36 36 36 36 52 36 36 36 36 36 36 ...   \n",
       "231235  [38 40 38 38 38 42 38 38 40 38 38 38 38 38 40 ...   \n",
       "231236                                               [36]   \n",
       "231237                                               [36]   \n",
       "\n",
       "                                    cpu_power_consumption  \n",
       "0       [ 948 1628 1650 1544 1260 1532 1418 1700 1710 ...  \n",
       "1       [1640 1604 1592 1364 1532 1508 1528 1476 1674 ...  \n",
       "2       [1654 1600 1606 1438 1506 1108 1496 1670 1680 ...  \n",
       "3       [108 182 178 182 190 174 188 186 190 176 176 1...  \n",
       "4       [ 82 182 178 180 170 168 168 192 196 166 196 1...  \n",
       "...                                                   ...  \n",
       "231233                                               [90]  \n",
       "231234  [ 96  92 100  90  92  94  98  94  96  90  90  ...  \n",
       "231235  [282 202 246 234 274 288 274 288 250 252 284 2...  \n",
       "231236                                               [46]  \n",
       "231237                                               [58]  \n",
       "\n",
       "[231238 rows x 78 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.astype({col: int for col in df.select_dtypes(include='bool').columns})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f0d2d4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values per column:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Total rows with any NaN: 0\n",
      "Total rows: 231238\n",
      "\n",
      "NaN in power consumption columns:\n",
      "node_power_consumption: 0\n",
      "mem_power_consumption: 0\n",
      "cpu_power_consumption: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in the dataframe\n",
    "print(\"NaN values per column:\")\n",
    "nan_counts = df.isnull().sum()\n",
    "print(nan_counts[nan_counts > 0])\n",
    "print(f\"\\nTotal rows with any NaN: {df.isnull().any(axis=1).sum()}\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "\n",
    "# Check specifically in power consumption columns\n",
    "print(\"\\nNaN in power consumption columns:\")\n",
    "power_cols = [col for col in df.columns if 'power_consumption' in col]\n",
    "for col in power_cols:\n",
    "    print(f\"{col}: {df[col].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "71ef6e37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns:\n",
      "['group_id', 'time_limit_scaled', 'num_nodes_req', 'has_req_nodes', 'num_cores_req', 'cores_per_task', 'num_tasks_final', 'num_gpus_req', 'mem_req', 'has_req_threads_per_core', 'is_shared_job', 'num_tasks_missing_or_inconsistent', 'partition_final', 'dow_0', 'dow_1', 'dow_2', 'dow_3', 'dow_4', 'dow_5', 'dow_6', 'dom_1', 'dom_2', 'dom_3', 'dom_4', 'dom_5', 'dom_6', 'dom_7', 'dom_8', 'dom_9', 'dom_10', 'dom_11', 'dom_12', 'dom_13', 'dom_14', 'dom_15', 'dom_16', 'dom_17', 'dom_18', 'dom_19', 'dom_20', 'dom_21', 'dom_22', 'dom_23', 'dom_24', 'dom_25', 'dom_26', 'dom_27', 'dom_28', 'dom_29', 'dom_30', 'dom_31', 'hour_0', 'hour_1', 'hour_2', 'hour_3', 'hour_4', 'hour_5', 'hour_6', 'hour_7', 'hour_8', 'hour_9', 'hour_10', 'hour_11', 'hour_12', 'hour_13', 'hour_14', 'hour_15', 'hour_16', 'hour_17', 'hour_18', 'hour_19', 'hour_20', 'hour_21', 'hour_22', 'hour_23', 'node_power_consumption', 'mem_power_consumption', 'cpu_power_consumption']\n"
     ]
    }
   ],
   "source": [
    "# Check what columns are actually in the dataframe\n",
    "print(\"Available columns:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d629750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e25ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target columns info:\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['node_power_consumption_mean', 'mem_power_consumption_mean',\\n       'cpu_power_consumption_mean'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Check target columns for issues\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTarget columns info:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mY_columns\u001b[49m\u001b[43m]\u001b[49m.info())\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTarget columns dtypes:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(df[Y_columns].dtypes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\envs\\ds-hpe-3-11\\Lib\\site-packages\\pandas\\core\\frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\envs\\ds-hpe-3-11\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\envs\\ds-hpe-3-11\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['node_power_consumption_mean', 'mem_power_consumption_mean',\\n       'cpu_power_consumption_mean'],\\n      dtype='object')] are in the [columns]\""
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Check target columns for issues\n",
    "print(\"Target columns info:\")\n",
    "print(df[Y_columns].info())\n",
    "print(\"\\nTarget columns dtypes:\")\n",
    "print(df[Y_columns].dtypes)\n",
    "print(\"\\nAny null values?\")\n",
    "print(df[Y_columns].isnull().sum())\n",
    "print(\"\\nSample values:\")\n",
    "print(df[Y_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c082e89e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      3\u001b[39m X,y = df[X_columns], df[Y_columns]\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m### FOR CLASSIC MODELS\u001b[39;00m\n\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Assuming you have your data in X (features) and y (labels)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m X_train, X_temp, y_train, y_temp = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=\u001b[32m0.5\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     11\u001b[39m scaler = RobustScaler()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\envs\\ds-hpe-3-11\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\envs\\ds-hpe-3-11\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2919\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2916\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2918\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\envs\\ds-hpe-3-11\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2499\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2496\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2500\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2503\u001b[39m     )\n\u001b[32m   2505\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# MAKE THE SPLITS\n",
    "\n",
    "X,y = df[X_columns], df[Y_columns]\n",
    "\n",
    "### FOR CLASSIC MODELS\n",
    "\n",
    "# Assuming you have your data in X (features) and y (labels)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit only on train!\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "### FOR TORCH MODELS\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device for tensors: {device}\")\n",
    "\n",
    "# Convert to tensors and move to GPU if available\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 1028\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad2dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataset, r\"C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\train_dataset.pt\")\n",
    "torch.save(val_dataset, r\"C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\val_dataset.pt\")\n",
    "torch.save(test_dataset, r\"C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\test_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a772fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches - Train: 158, Val: 34, Test: 34\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of batches - Train: {len(train_loader)}, Val: {len(val_loader)}, Test: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d04a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./models/code_models/')\n",
    "\n",
    "import sklearn_models\n",
    "import torch_models\n",
    "import training_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71788246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReduceLROnPlateau patch applied successfully\n"
     ]
    }
   ],
   "source": [
    "# Patch for ReduceLROnPlateau verbose parameter issue\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "original_init = lr_scheduler.ReduceLROnPlateau.__init__\n",
    "\n",
    "def patched_init(self, optimizer, mode='min', factor=0.1, patience=10,\n",
    "                 threshold=1e-4, threshold_mode='rel', cooldown=0,\n",
    "                 min_lr=0, eps=1e-8, verbose=False):\n",
    "    # Remove verbose parameter as it's deprecated in newer PyTorch versions\n",
    "    original_init(self, optimizer, mode=mode, factor=factor, patience=patience,\n",
    "                  threshold=threshold, threshold_mode=threshold_mode, \n",
    "                  cooldown=cooldown, min_lr=min_lr, eps=eps)\n",
    "\n",
    "# Apply the patch\n",
    "lr_scheduler.ReduceLROnPlateau.__init__ = patched_init\n",
    "print(\"ReduceLROnPlateau patch applied successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb0cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Jaime\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup WandB\n",
    "import wandb\n",
    "\n",
    "# Login to WandB (you'll need to provide your API key)\n",
    "# You can get your API key from https://wandb.ai/authorize\n",
    "# wandb.login()\n",
    "\n",
    "# Alternatively, set your API key directly (not recommended for shared notebooks):\n",
    "wandb.login(key=\"921066fcdeb3dbcc365e03ada59333e0a5f57021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd453931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart kernel after conda installation\n",
    "#import IPython\n",
    "#IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b006a97",
   "metadata": {},
   "source": [
    "# SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78398ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model = sklearn_models.get_random_forest()\n",
    "\n",
    "# rf_trainer = training_utils.SklearnTrainer(\n",
    "#     model=rf_model,\n",
    "#     model_name=\"RandomForest_Default\",\n",
    "#     project_name=\"Test\",\n",
    "#     entity=\"iqbalch-universidad-carlos-iii-de-madrid\" \n",
    "# )\n",
    "\n",
    "# rf_model, rf_metrics = rf_trainer.train(\n",
    "#     X_train_scaled, y_train,\n",
    "#     X_val_scaled, y_val,\n",
    "#     config= rf_model.get_params()\n",
    "# )\n",
    "\n",
    "# print(\"\\nValidation Metrics:\")\n",
    "# for key, value in rf_metrics.items():\n",
    "#     if 'val' in key:\n",
    "#         print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# test_metrics, test_predictions = training_utils.evaluate_model(\n",
    "#     rf_model, X_test_scaled, y_test, model_type=\"sklearn\"\n",
    "# )\n",
    "\n",
    "# print(\"\\nTest Set Metrics:\")\n",
    "# for key, value in test_metrics.items():\n",
    "#     print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d78abd",
   "metadata": {},
   "source": [
    "# TORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41115b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f14247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: 75\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 5060 Laptop GPU\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Attention_MLP</strong> at: <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/DS_HPE/runs/73u66w8g' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/DS_HPE/runs/73u66w8g</a><br> View project at: <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/DS_HPE' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/DS_HPE</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251202_013250-73u66w8g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\wandb\\run-20251202_013547-fuhh86ae</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/DS_HPE/runs/fuhh86ae' target=\"_blank\">Attention_MLP</a></strong> to <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/DS_HPE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/DS_HPE' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/DS_HPE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/DS_HPE/runs/fuhh86ae' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/DS_HPE/runs/fuhh86ae</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     13\u001b[39m siple_mlp_model = torch_models.AttentionMLP(\n\u001b[32m     14\u001b[39m     input_dim=input_dim,\n\u001b[32m     15\u001b[39m     hidden_dim=\u001b[32m128\u001b[39m,  \u001b[38;5;66;03m# Must be divisible by num_heads\u001b[39;00m\n\u001b[32m     16\u001b[39m     num_heads=\u001b[32m8\u001b[39m      \u001b[38;5;66;03m# 128 / 8 = 16 (valid)\u001b[39;00m\n\u001b[32m     17\u001b[39m ).to(device)  \u001b[38;5;66;03m# Move model to GPU\u001b[39;00m\n\u001b[32m     19\u001b[39m trainer = training_utils.PyTorchTrainer(\n\u001b[32m     20\u001b[39m     model=siple_mlp_model,\n\u001b[32m     21\u001b[39m     model_name=\u001b[33m\"\u001b[39m\u001b[33mAttention_MLP\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     22\u001b[39m     project_name=\u001b[33m\"\u001b[39m\u001b[33mDS_HPE\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m     entity = \u001b[33m\"\u001b[39m\u001b[33m100451397-universidad-carlos-iii-de-madrid\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Use None to automatically use your default WandB account\u001b[39;00m\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m torch_model, torch_best_metrics = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0001\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m80\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Evaluate on test\u001b[39;00m\n\u001b[32m     36\u001b[39m torch_test_metrics, _ = training_utils.evaluate_model(\n\u001b[32m     37\u001b[39m     torch_model, X_test_scaled, y_test, model_type=\u001b[33m\"\u001b[39m\u001b[33mpytorch\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     38\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\./models/code_models\\training_utils.py:179\u001b[39m, in \u001b[36mPyTorchTrainer.train\u001b[39m\u001b[34m(self, train_loader, val_loader, epochs, lr, weight_decay, patience, config)\u001b[39m\n\u001b[32m    176\u001b[39m train_metrics = \u001b[38;5;28mself\u001b[39m._train_epoch(train_loader, criterion, optimizer)\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# Validate\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m val_metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# Learning rate scheduling\u001b[39;00m\n\u001b[32m    182\u001b[39m scheduler.step(val_metrics[\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\./models/code_models\\training_utils.py:276\u001b[39m, in \u001b[36mPyTorchTrainer._validate_epoch\u001b[39m\u001b[34m(self, val_loader, criterion)\u001b[39m\n\u001b[32m    274\u001b[39m target_names = [\u001b[33m\"\u001b[39m\u001b[33mmean_power\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmin_power\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmax_power\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(target_names):\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     rmse = np.sqrt(\u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_targets\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    277\u001b[39m     mae = mean_absolute_error(all_targets[:, i], all_preds[:, i])\n\u001b[32m    278\u001b[39m     r2 = r2_score(all_targets[:, i], all_preds[:, i])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\envs\\ds-hpe-3-11\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\envs\\ds-hpe-3-11\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:580\u001b[39m, in \u001b[36mmean_squared_error\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput)\u001b[39m\n\u001b[32m    530\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[32m    531\u001b[39m \n\u001b[32m    532\u001b[39m \u001b[33;03mRead more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    576\u001b[39m \u001b[33;03m0.825...\u001b[39;00m\n\u001b[32m    577\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    578\u001b[39m xp, _ = get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001b[32m    579\u001b[39m _, y_true, y_pred, sample_weight, multioutput = (\n\u001b[32m--> \u001b[39m\u001b[32m580\u001b[39m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    583\u001b[39m )\n\u001b[32m    584\u001b[39m output_errors = _average((y_true - y_pred) ** \u001b[32m2\u001b[39m, axis=\u001b[32m0\u001b[39m, weights=sample_weight)\n\u001b[32m    586\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(multioutput, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\envs\\ds-hpe-3-11\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:209\u001b[39m, in \u001b[36m_check_reg_targets_with_floating_dtype\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Ensures y_true, y_pred, and sample_weight correspond to same regression task.\u001b[39;00m\n\u001b[32m    161\u001b[39m \n\u001b[32m    162\u001b[39m \u001b[33;03mExtends `_check_reg_targets` by automatically selecting a suitable floating-point\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    205\u001b[39m \u001b[33;03m    correct keyword.\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    207\u001b[39m dtype_name = _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp=xp)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m y_type, y_true, y_pred, sample_weight, multioutput = \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y_type, y_true, y_pred, sample_weight, multioutput\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\envs\\ds-hpe-3-11\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:115\u001b[39m, in \u001b[36m_check_reg_targets\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, dtype, xp)\u001b[39m\n\u001b[32m    112\u001b[39m xp, _ = get_namespace(y_true, y_pred, multioutput, xp=xp)\n\u001b[32m    114\u001b[39m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m y_true = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m y_pred = check_array(y_pred, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=dtype)\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\envs\\ds-hpe-3-11\\Lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\envs\\ds-hpe-3-11\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\envs\\ds-hpe-3-11\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "input_dim = X_train_scaled.shape[1]\n",
    "print(f\"Input dimension: {input_dim}\")\n",
    "\n",
    "# Check GPU availability and set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Create model with hidden_dim divisible by num_heads\n",
    "# Default hidden_dim is 128, num_heads is 8 (128/8=16 ✓)\n",
    "# If you need custom values, ensure hidden_dim % num_heads == 0\n",
    "siple_mlp_model = torch_models.AttentionMLP(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=128,  # Must be divisible by num_heads\n",
    "    num_heads=8      # 128 / 8 = 16 (valid)\n",
    ").to(device)  # Move model to GPU\n",
    "\n",
    "trainer = training_utils.PyTorchTrainer(\n",
    "    model=siple_mlp_model,\n",
    "    model_name=\"Attention_MLP\",\n",
    "    project_name=\"DS_HPE\",\n",
    "    entity = \"100451397-universidad-carlos-iii-de-madrid\"  # Use None to automatically use your default WandB account\n",
    ")\n",
    "\n",
    "torch_model, torch_best_metrics = trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=150,\n",
    "    lr=0.0001,\n",
    "    weight_decay=1e-5,\n",
    "    patience=80,\n",
    ")\n",
    "\n",
    "# Evaluate on test\n",
    "torch_test_metrics, _ = training_utils.evaluate_model(\n",
    "    torch_model, X_test_scaled, y_test, model_type=\"pytorch\"\n",
    ")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"RMSE: {torch_test_metrics['test_rmse_mean']:.4f}\")\n",
    "print(f\"MAE: {torch_test_metrics['test_mae_mean']:.4f}\")\n",
    "print(f\"R2: {torch_test_metrics['test_r2_mean']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c552db",
<<<<<<< Updated upstream
=======
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport random\\n\\nimport wandb\\n\\n# Start a new wandb run to track this script.\\nrun = wandb.init(\\n    # Set the wandb entity where your project will be logged (use your username).\\n    entity=\"100451397\",  # Your personal WandB username\\n    # Set the wandb project where this run will be logged.\\n    project=\"DS_HPE\",\\n    # Track hyperparameters and run metadata.\\n    config={\\n        \"learning_rate\": 0.02,\\n        \"architecture\": \"CNN\",\\n        \"dataset\": \"CIFAR-100\",\\n        \"epochs\": 10,\\n    },\\n)\\n\\n# Simulate training.\\nepochs = 10\\noffset = random.random() / 5\\nfor epoch in range(2, epochs):\\n    acc = 1 - 2**-epoch - random.random() / epoch - offset\\n    loss = 2**-epoch + random.random() / epoch + offset\\n\\n    # Log metrics to wandb.\\n    run.log({\"acc\": acc, \"loss\": loss})\\n\\n# Finish the run and upload any remaining data.\\nrun.finish()\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import random\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Start a new wandb run to track this script.\n",
    "run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (use your username).\n",
    "    entity=\"100451397\",  # Your personal WandB username\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"DS_HPE\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config={\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"architecture\": \"CNN\",\n",
    "        \"dataset\": \"CIFAR-100\",\n",
    "        \"epochs\": 10,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Simulate training.\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2**-epoch - random.random() / epoch - offset\n",
    "    loss = 2**-epoch + random.random() / epoch + offset\n",
    "\n",
    "    # Log metrics to wandb.\n",
    "    run.log({\"acc\": acc, \"loss\": loss})\n",
    "\n",
    "# Finish the run and upload any remaining data.\n",
    "run.finish()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268fb16c",
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport random\\n\\nimport wandb\\n\\n# Start a new wandb run to track this script.\\nrun = wandb.init(\\n    # Set the wandb entity where your project will be logged (use your username).\\n    entity=\"100451397\",  # Your personal WandB username\\n    # Set the wandb project where this run will be logged.\\n    project=\"DS_HPE\",\\n    # Track hyperparameters and run metadata.\\n    config={\\n        \"learning_rate\": 0.02,\\n        \"architecture\": \"CNN\",\\n        \"dataset\": \"CIFAR-100\",\\n        \"epochs\": 10,\\n    },\\n)\\n\\n# Simulate training.\\nepochs = 10\\noffset = random.random() / 5\\nfor epoch in range(2, epochs):\\n    acc = 1 - 2**-epoch - random.random() / epoch - offset\\n    loss = 2**-epoch + random.random() / epoch + offset\\n\\n    # Log metrics to wandb.\\n    run.log({\"acc\": acc, \"loss\": loss})\\n\\n# Finish the run and upload any remaining data.\\nrun.finish()\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< Updated upstream
    "\"\"\"\n",
    "import random\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Start a new wandb run to track this script.\n",
    "run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (use your username).\n",
    "    entity=\"100451397\",  # Your personal WandB username\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"DS_HPE\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config={\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"architecture\": \"CNN\",\n",
    "        \"dataset\": \"CIFAR-100\",\n",
    "        \"epochs\": 10,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Simulate training.\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2**-epoch - random.random() / epoch - offset\n",
    "    loss = 2**-epoch + random.random() / epoch + offset\n",
    "\n",
    "    # Log metrics to wandb.\n",
    "    run.log({\"acc\": acc, \"loss\": loss})\n",
    "\n",
    "# Finish the run and upload any remaining data.\n",
    "run.finish()\n",
    "\"\"\""
=======
    "torch.save(siple_mlp_model.state_dict(), r'C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\model.pt')"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268fb16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(siple_mlp_model.state_dict(), r'C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\model.pt')"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d447889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just load the data\n",
    "df = pd.read_parquet(\"job_table.parquet\")"
   ]
  }
 ],
 "metadata": {
<<<<<<< Updated upstream
  "language_info": {
   "name": "python"
=======
  "kernelspec": {
   "display_name": "ds-hpe-3-11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
<<<<<<< Updated upstream
>>>>>>> Stashed changes
=======
>>>>>>> Stashed changes
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
