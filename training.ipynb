{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2228800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e187a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "data_path = r\"C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\final_dataset.csv\"\n",
    "data_target = r\"C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\data_to_train_meantime.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc1dc12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaime\\AppData\\Local\\Temp\\ipykernel_6660\\3487717889.py:3: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n"
     ]
    }
   ],
   "source": [
    "# LOAD THE ESSENTIALS\n",
    "\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea940766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>group_id</th>\n",
       "      <th>group_major</th>\n",
       "      <th>submit_time</th>\n",
       "      <th>time_limit_cat</th>\n",
       "      <th>time_limit_scaled</th>\n",
       "      <th>num_nodes_req</th>\n",
       "      <th>has_req_nodes</th>\n",
       "      <th>num_cores_req</th>\n",
       "      <th>cores_per_task</th>\n",
       "      <th>num_tasks_final</th>\n",
       "      <th>num_gpus_req</th>\n",
       "      <th>mem_req</th>\n",
       "      <th>has_req_threads_per_core</th>\n",
       "      <th>is_shared_job</th>\n",
       "      <th>num_tasks_missing_or_inconsistent</th>\n",
       "      <th>partition_final</th>\n",
       "      <th>qos_final</th>\n",
       "      <th>dow_0</th>\n",
       "      <th>dow_1</th>\n",
       "      <th>dow_2</th>\n",
       "      <th>dow_3</th>\n",
       "      <th>dow_4</th>\n",
       "      <th>dow_5</th>\n",
       "      <th>dow_6</th>\n",
       "      <th>dom_1</th>\n",
       "      <th>dom_2</th>\n",
       "      <th>dom_3</th>\n",
       "      <th>dom_4</th>\n",
       "      <th>dom_5</th>\n",
       "      <th>dom_6</th>\n",
       "      <th>dom_7</th>\n",
       "      <th>dom_8</th>\n",
       "      <th>dom_9</th>\n",
       "      <th>dom_10</th>\n",
       "      <th>dom_11</th>\n",
       "      <th>dom_12</th>\n",
       "      <th>dom_13</th>\n",
       "      <th>dom_14</th>\n",
       "      <th>dom_15</th>\n",
       "      <th>dom_16</th>\n",
       "      <th>dom_17</th>\n",
       "      <th>dom_18</th>\n",
       "      <th>dom_19</th>\n",
       "      <th>dom_20</th>\n",
       "      <th>dom_21</th>\n",
       "      <th>dom_22</th>\n",
       "      <th>dom_23</th>\n",
       "      <th>dom_24</th>\n",
       "      <th>dom_25</th>\n",
       "      <th>dom_26</th>\n",
       "      <th>dom_27</th>\n",
       "      <th>dom_28</th>\n",
       "      <th>dom_29</th>\n",
       "      <th>dom_30</th>\n",
       "      <th>dom_31</th>\n",
       "      <th>hour_0</th>\n",
       "      <th>hour_1</th>\n",
       "      <th>hour_2</th>\n",
       "      <th>hour_3</th>\n",
       "      <th>hour_4</th>\n",
       "      <th>hour_5</th>\n",
       "      <th>hour_6</th>\n",
       "      <th>hour_7</th>\n",
       "      <th>hour_8</th>\n",
       "      <th>hour_9</th>\n",
       "      <th>hour_10</th>\n",
       "      <th>hour_11</th>\n",
       "      <th>hour_12</th>\n",
       "      <th>hour_13</th>\n",
       "      <th>hour_14</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>node_power_consumption</th>\n",
       "      <th>mem_power_consumption</th>\n",
       "      <th>cpu_power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25200</td>\n",
       "      <td>main</td>\n",
       "      <td>2020-05-31 22:09:29+00:00</td>\n",
       "      <td>medium (1–5h)</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[7970 8450 8460 8470 7440 8470 8460 8470 7910 ...</td>\n",
       "      <td>[418 724 724 678 556 654 606 600 600 488 606 4...</td>\n",
       "      <td>[ 948 1628 1650 1544 1260 1532 1418 1700 1710 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25200</td>\n",
       "      <td>main</td>\n",
       "      <td>2020-05-31 22:22:08+00:00</td>\n",
       "      <td>medium (1–5h)</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[7970 8430 7940 8480 7460 8490 6890 8480 8480 ...</td>\n",
       "      <td>[720 738 736 614 720 642 632 524 598 628 616 5...</td>\n",
       "      <td>[1640 1604 1592 1364 1532 1508 1528 1476 1674 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>main</td>\n",
       "      <td>2020-05-31 22:41:38+00:00</td>\n",
       "      <td>medium (1–5h)</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[7950 7970 8500 8480 8470 6900 8460 8450 8470 ...</td>\n",
       "      <td>[672 720 716 630 674 474 644 606 602 564 650 5...</td>\n",
       "      <td>[1654 1600 1606 1438 1506 1108 1496 1670 1680 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>25200</td>\n",
       "      <td>main</td>\n",
       "      <td>2020-05-31 23:26:23+00:00</td>\n",
       "      <td>short (&lt;1h)</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[860 860 860 860 860 860 860 860 860 860 860 8...</td>\n",
       "      <td>[38 40 46 44 48 40 44 46 42 40 40 40 38 46 44 ...</td>\n",
       "      <td>[108 182 178 182 190 174 188 186 190 176 176 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>25200</td>\n",
       "      <td>main</td>\n",
       "      <td>2020-05-31 23:08:01+00:00</td>\n",
       "      <td>short (&lt;1h)</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[860 860 860 860 860 860 860 860 860 860 860 8...</td>\n",
       "      <td>[36 44 42 42 44 40 44 42 50 42 42 46 48 42 44 ...</td>\n",
       "      <td>[ 82 182 178 180 170 168 168 192 196 166 196 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  group_id group_major                submit_time time_limit_cat  \\\n",
       "0           0     25200        main  2020-05-31 22:09:29+00:00  medium (1–5h)   \n",
       "1           1     25200        main  2020-05-31 22:22:08+00:00  medium (1–5h)   \n",
       "2           2     25200        main  2020-05-31 22:41:38+00:00  medium (1–5h)   \n",
       "3           3     25200        main  2020-05-31 23:26:23+00:00    short (<1h)   \n",
       "4           4     25200        main  2020-05-31 23:08:01+00:00    short (<1h)   \n",
       "\n",
       "   time_limit_scaled  num_nodes_req  has_req_nodes  num_cores_req  \\\n",
       "0          -0.007838             16              0            256   \n",
       "1          -0.007838             16              0            256   \n",
       "2          -0.007838             16              0            256   \n",
       "3          -1.243395              1              0             32   \n",
       "4          -1.243395              1              0             32   \n",
       "\n",
       "   cores_per_task  num_tasks_final  num_gpus_req  mem_req  \\\n",
       "0               4               64            64      475   \n",
       "1               4               64            64      475   \n",
       "2               4               64            64      475   \n",
       "3              32                0             4       59   \n",
       "4              32                0             4       59   \n",
       "\n",
       "   has_req_threads_per_core  is_shared_job  num_tasks_missing_or_inconsistent  \\\n",
       "0                         0              0                              False   \n",
       "1                         0              0                              False   \n",
       "2                         0              0                              False   \n",
       "3                         0              1                               True   \n",
       "4                         0              1                               True   \n",
       "\n",
       "   partition_final qos_final  dow_0  dow_1  dow_2  dow_3  dow_4  dow_5  dow_6  \\\n",
       "0                1         1  False  False  False  False  False  False   True   \n",
       "1                1         1  False  False  False  False  False  False   True   \n",
       "2                1         1  False  False  False  False  False  False   True   \n",
       "3                1         1  False  False  False  False  False  False   True   \n",
       "4                1         1  False  False  False  False  False  False   True   \n",
       "\n",
       "   dom_1  dom_2  dom_3  dom_4  dom_5  dom_6  dom_7  dom_8  dom_9  dom_10  \\\n",
       "0  False  False  False  False  False  False  False  False  False   False   \n",
       "1  False  False  False  False  False  False  False  False  False   False   \n",
       "2  False  False  False  False  False  False  False  False  False   False   \n",
       "3  False  False  False  False  False  False  False  False  False   False   \n",
       "4  False  False  False  False  False  False  False  False  False   False   \n",
       "\n",
       "   dom_11  dom_12  dom_13  dom_14  dom_15  dom_16  dom_17  dom_18  dom_19  \\\n",
       "0   False   False   False   False   False   False   False   False   False   \n",
       "1   False   False   False   False   False   False   False   False   False   \n",
       "2   False   False   False   False   False   False   False   False   False   \n",
       "3   False   False   False   False   False   False   False   False   False   \n",
       "4   False   False   False   False   False   False   False   False   False   \n",
       "\n",
       "   dom_20  dom_21  dom_22  dom_23  dom_24  dom_25  dom_26  dom_27  dom_28  \\\n",
       "0   False   False   False   False   False   False   False   False   False   \n",
       "1   False   False   False   False   False   False   False   False   False   \n",
       "2   False   False   False   False   False   False   False   False   False   \n",
       "3   False   False   False   False   False   False   False   False   False   \n",
       "4   False   False   False   False   False   False   False   False   False   \n",
       "\n",
       "   dom_29  dom_30  dom_31  hour_0  hour_1  hour_2  hour_3  hour_4  hour_5  \\\n",
       "0   False   False    True   False   False   False   False   False   False   \n",
       "1   False   False    True   False   False   False   False   False   False   \n",
       "2   False   False    True   False   False   False   False   False   False   \n",
       "3   False   False    True   False   False   False   False   False   False   \n",
       "4   False   False    True   False   False   False   False   False   False   \n",
       "\n",
       "   hour_6  hour_7  hour_8  hour_9  hour_10  hour_11  hour_12  hour_13  \\\n",
       "0   False   False   False   False    False    False    False    False   \n",
       "1   False   False   False   False    False    False    False    False   \n",
       "2   False   False   False   False    False    False    False    False   \n",
       "3   False   False   False   False    False    False    False    False   \n",
       "4   False   False   False   False    False    False    False    False   \n",
       "\n",
       "   hour_14  hour_15  hour_16  hour_17  hour_18  hour_19  hour_20  hour_21  \\\n",
       "0    False    False    False    False    False    False    False    False   \n",
       "1    False    False    False    False    False    False    False    False   \n",
       "2    False    False    False    False    False    False    False    False   \n",
       "3    False    False    False    False    False    False    False    False   \n",
       "4    False    False    False    False    False    False    False    False   \n",
       "\n",
       "   hour_22  hour_23                             node_power_consumption  \\\n",
       "0     True    False  [7970 8450 8460 8470 7440 8470 8460 8470 7910 ...   \n",
       "1     True    False  [7970 8430 7940 8480 7460 8490 6890 8480 8480 ...   \n",
       "2     True    False  [7950 7970 8500 8480 8470 6900 8460 8450 8470 ...   \n",
       "3    False     True  [860 860 860 860 860 860 860 860 860 860 860 8...   \n",
       "4    False     True  [860 860 860 860 860 860 860 860 860 860 860 8...   \n",
       "\n",
       "                               mem_power_consumption  \\\n",
       "0  [418 724 724 678 556 654 606 600 600 488 606 4...   \n",
       "1  [720 738 736 614 720 642 632 524 598 628 616 5...   \n",
       "2  [672 720 716 630 674 474 644 606 602 564 650 5...   \n",
       "3  [38 40 46 44 48 40 44 46 42 40 40 40 38 46 44 ...   \n",
       "4  [36 44 42 42 44 40 44 42 50 42 42 46 48 42 44 ...   \n",
       "\n",
       "                               cpu_power_consumption  \n",
       "0  [ 948 1628 1650 1544 1260 1532 1418 1700 1710 ...  \n",
       "1  [1640 1604 1592 1364 1532 1508 1528 1476 1674 ...  \n",
       "2  [1654 1600 1606 1438 1506 1108 1496 1670 1680 ...  \n",
       "3  [108 182 178 182 190 174 188 186 190 176 176 1...  \n",
       "4  [ 82 182 178 180 170 168 168 192 196 166 196 1...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff6621c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Unnamed: 0\",\"qos_final\",\"submit_time\", \"time_limit_cat\", \"group_major\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8e93e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>time_limit_scaled</th>\n",
       "      <th>num_nodes_req</th>\n",
       "      <th>has_req_nodes</th>\n",
       "      <th>num_cores_req</th>\n",
       "      <th>cores_per_task</th>\n",
       "      <th>num_tasks_final</th>\n",
       "      <th>num_gpus_req</th>\n",
       "      <th>mem_req</th>\n",
       "      <th>has_req_threads_per_core</th>\n",
       "      <th>is_shared_job</th>\n",
       "      <th>num_tasks_missing_or_inconsistent</th>\n",
       "      <th>partition_final</th>\n",
       "      <th>dow_0</th>\n",
       "      <th>dow_1</th>\n",
       "      <th>dow_2</th>\n",
       "      <th>dow_3</th>\n",
       "      <th>dow_4</th>\n",
       "      <th>dow_5</th>\n",
       "      <th>dow_6</th>\n",
       "      <th>dom_1</th>\n",
       "      <th>dom_2</th>\n",
       "      <th>dom_3</th>\n",
       "      <th>dom_4</th>\n",
       "      <th>dom_5</th>\n",
       "      <th>dom_6</th>\n",
       "      <th>dom_7</th>\n",
       "      <th>dom_8</th>\n",
       "      <th>dom_9</th>\n",
       "      <th>dom_10</th>\n",
       "      <th>dom_11</th>\n",
       "      <th>dom_12</th>\n",
       "      <th>dom_13</th>\n",
       "      <th>dom_14</th>\n",
       "      <th>dom_15</th>\n",
       "      <th>dom_16</th>\n",
       "      <th>dom_17</th>\n",
       "      <th>dom_18</th>\n",
       "      <th>dom_19</th>\n",
       "      <th>dom_20</th>\n",
       "      <th>dom_21</th>\n",
       "      <th>dom_22</th>\n",
       "      <th>dom_23</th>\n",
       "      <th>dom_24</th>\n",
       "      <th>dom_25</th>\n",
       "      <th>dom_26</th>\n",
       "      <th>dom_27</th>\n",
       "      <th>dom_28</th>\n",
       "      <th>dom_29</th>\n",
       "      <th>dom_30</th>\n",
       "      <th>dom_31</th>\n",
       "      <th>hour_0</th>\n",
       "      <th>hour_1</th>\n",
       "      <th>hour_2</th>\n",
       "      <th>hour_3</th>\n",
       "      <th>hour_4</th>\n",
       "      <th>hour_5</th>\n",
       "      <th>hour_6</th>\n",
       "      <th>hour_7</th>\n",
       "      <th>hour_8</th>\n",
       "      <th>hour_9</th>\n",
       "      <th>hour_10</th>\n",
       "      <th>hour_11</th>\n",
       "      <th>hour_12</th>\n",
       "      <th>hour_13</th>\n",
       "      <th>hour_14</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>node_power_consumption</th>\n",
       "      <th>mem_power_consumption</th>\n",
       "      <th>cpu_power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25200</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[7970 8450 8460 8470 7440 8470 8460 8470 7910 ...</td>\n",
       "      <td>[418 724 724 678 556 654 606 600 600 488 606 4...</td>\n",
       "      <td>[ 948 1628 1650 1544 1260 1532 1418 1700 1710 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25200</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[7970 8430 7940 8480 7460 8490 6890 8480 8480 ...</td>\n",
       "      <td>[720 738 736 614 720 642 632 524 598 628 616 5...</td>\n",
       "      <td>[1640 1604 1592 1364 1532 1508 1528 1476 1674 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25200</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[7950 7970 8500 8480 8470 6900 8460 8450 8470 ...</td>\n",
       "      <td>[672 720 716 630 674 474 644 606 602 564 650 5...</td>\n",
       "      <td>[1654 1600 1606 1438 1506 1108 1496 1670 1680 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25200</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[860 860 860 860 860 860 860 860 860 860 860 8...</td>\n",
       "      <td>[38 40 46 44 48 40 44 46 42 40 40 40 38 46 44 ...</td>\n",
       "      <td>[108 182 178 182 190 174 188 186 190 176 176 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25200</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[860 860 860 860 860 860 860 860 860 860 860 8...</td>\n",
       "      <td>[36 44 42 42 44 40 44 42 50 42 42 46 48 42 44 ...</td>\n",
       "      <td>[ 82 182 178 180 170 168 168 192 196 166 196 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231233</th>\n",
       "      <td>25200</td>\n",
       "      <td>0.944404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[920]</td>\n",
       "      <td>[36]</td>\n",
       "      <td>[90]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231234</th>\n",
       "      <td>25200</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[870 860 860 860 860 870 860 870 860 860 860 8...</td>\n",
       "      <td>[44 36 36 36 36 36 36 36 52 36 36 36 36 36 36 ...</td>\n",
       "      <td>[ 96  92 100  90  92  94  98  94  96  90  90  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231235</th>\n",
       "      <td>25200</td>\n",
       "      <td>0.386115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 620  620  610  630  630  630  620  620  630 ...</td>\n",
       "      <td>[38 40 38 38 38 42 38 38 40 38 38 38 38 38 40 ...</td>\n",
       "      <td>[282 202 246 234 274 288 274 288 250 252 284 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231236</th>\n",
       "      <td>25200</td>\n",
       "      <td>0.944404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[860]</td>\n",
       "      <td>[36]</td>\n",
       "      <td>[46]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231237</th>\n",
       "      <td>25200</td>\n",
       "      <td>0.944404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[900]</td>\n",
       "      <td>[36]</td>\n",
       "      <td>[58]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231238 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        group_id  time_limit_scaled  num_nodes_req  has_req_nodes  \\\n",
       "0          25200          -0.007838             16              0   \n",
       "1          25200          -0.007838             16              0   \n",
       "2          25200          -0.007838             16              0   \n",
       "3          25200          -1.243395              1              0   \n",
       "4          25200          -1.243395              1              0   \n",
       "...          ...                ...            ...            ...   \n",
       "231233     25200           0.944404              1              0   \n",
       "231234     25200          -1.243395              1              1   \n",
       "231235     25200           0.386115              1              0   \n",
       "231236     25200           0.944404              1              0   \n",
       "231237     25200           0.944404              1              0   \n",
       "\n",
       "        num_cores_req  cores_per_task  num_tasks_final  num_gpus_req  mem_req  \\\n",
       "0                 256               4               64            64      475   \n",
       "1                 256               4               64            64      475   \n",
       "2                 256               4               64            64      475   \n",
       "3                  32              32                0             4       59   \n",
       "4                  32              32                0             4       59   \n",
       "...               ...             ...              ...           ...      ...   \n",
       "231233            128              32                4             4      237   \n",
       "231234              4               1                4             4        7   \n",
       "231235            128              16                8             4      234   \n",
       "231236            128              32                4             4      237   \n",
       "231237            128              32                4             4      237   \n",
       "\n",
       "        has_req_threads_per_core  is_shared_job  \\\n",
       "0                              0              0   \n",
       "1                              0              0   \n",
       "2                              0              0   \n",
       "3                              0              1   \n",
       "4                              0              1   \n",
       "...                          ...            ...   \n",
       "231233                         0              1   \n",
       "231234                         0              0   \n",
       "231235                         0              1   \n",
       "231236                         0              1   \n",
       "231237                         0              1   \n",
       "\n",
       "        num_tasks_missing_or_inconsistent  partition_final  dow_0  dow_1  \\\n",
       "0                                       0                1      0      0   \n",
       "1                                       0                1      0      0   \n",
       "2                                       0                1      0      0   \n",
       "3                                       1                1      0      0   \n",
       "4                                       1                1      0      0   \n",
       "...                                   ...              ...    ...    ...   \n",
       "231233                                  0                1      0      0   \n",
       "231234                                  0                1      0      0   \n",
       "231235                                  0                1      0      0   \n",
       "231236                                  0                1      0      0   \n",
       "231237                                  0                1      0      0   \n",
       "\n",
       "        dow_2  dow_3  dow_4  dow_5  dow_6  dom_1  dom_2  dom_3  dom_4  dom_5  \\\n",
       "0           0      0      0      0      1      0      0      0      0      0   \n",
       "1           0      0      0      0      1      0      0      0      0      0   \n",
       "2           0      0      0      0      1      0      0      0      0      0   \n",
       "3           0      0      0      0      1      0      0      0      0      0   \n",
       "4           0      0      0      0      1      0      0      0      0      0   \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "231233      1      0      0      0      0      0      0      0      0      0   \n",
       "231234      1      0      0      0      0      0      0      0      0      0   \n",
       "231235      1      0      0      0      0      0      0      0      0      0   \n",
       "231236      1      0      0      0      0      0      0      0      0      0   \n",
       "231237      1      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "        dom_6  dom_7  dom_8  dom_9  dom_10  dom_11  dom_12  dom_13  dom_14  \\\n",
       "0           0      0      0      0       0       0       0       0       0   \n",
       "1           0      0      0      0       0       0       0       0       0   \n",
       "2           0      0      0      0       0       0       0       0       0   \n",
       "3           0      0      0      0       0       0       0       0       0   \n",
       "4           0      0      0      0       0       0       0       0       0   \n",
       "...       ...    ...    ...    ...     ...     ...     ...     ...     ...   \n",
       "231233      0      1      0      0       0       0       0       0       0   \n",
       "231234      0      1      0      0       0       0       0       0       0   \n",
       "231235      0      1      0      0       0       0       0       0       0   \n",
       "231236      0      1      0      0       0       0       0       0       0   \n",
       "231237      0      1      0      0       0       0       0       0       0   \n",
       "\n",
       "        dom_15  dom_16  dom_17  dom_18  dom_19  dom_20  dom_21  dom_22  \\\n",
       "0            0       0       0       0       0       0       0       0   \n",
       "1            0       0       0       0       0       0       0       0   \n",
       "2            0       0       0       0       0       0       0       0   \n",
       "3            0       0       0       0       0       0       0       0   \n",
       "4            0       0       0       0       0       0       0       0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "231233       0       0       0       0       0       0       0       0   \n",
       "231234       0       0       0       0       0       0       0       0   \n",
       "231235       0       0       0       0       0       0       0       0   \n",
       "231236       0       0       0       0       0       0       0       0   \n",
       "231237       0       0       0       0       0       0       0       0   \n",
       "\n",
       "        dom_23  dom_24  dom_25  dom_26  dom_27  dom_28  dom_29  dom_30  \\\n",
       "0            0       0       0       0       0       0       0       0   \n",
       "1            0       0       0       0       0       0       0       0   \n",
       "2            0       0       0       0       0       0       0       0   \n",
       "3            0       0       0       0       0       0       0       0   \n",
       "4            0       0       0       0       0       0       0       0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "231233       0       0       0       0       0       0       0       0   \n",
       "231234       0       0       0       0       0       0       0       0   \n",
       "231235       0       0       0       0       0       0       0       0   \n",
       "231236       0       0       0       0       0       0       0       0   \n",
       "231237       0       0       0       0       0       0       0       0   \n",
       "\n",
       "        dom_31  hour_0  hour_1  hour_2  hour_3  hour_4  hour_5  hour_6  \\\n",
       "0            1       0       0       0       0       0       0       0   \n",
       "1            1       0       0       0       0       0       0       0   \n",
       "2            1       0       0       0       0       0       0       0   \n",
       "3            1       0       0       0       0       0       0       0   \n",
       "4            1       0       0       0       0       0       0       0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "231233       0       0       0       0       0       0       1       0   \n",
       "231234       0       0       0       0       0       0       0       0   \n",
       "231235       0       0       0       0       0       0       0       0   \n",
       "231236       0       0       0       0       0       0       0       1   \n",
       "231237       0       0       1       0       0       0       0       0   \n",
       "\n",
       "        hour_7  hour_8  hour_9  hour_10  hour_11  hour_12  hour_13  hour_14  \\\n",
       "0            0       0       0        0        0        0        0        0   \n",
       "1            0       0       0        0        0        0        0        0   \n",
       "2            0       0       0        0        0        0        0        0   \n",
       "3            0       0       0        0        0        0        0        0   \n",
       "4            0       0       0        0        0        0        0        0   \n",
       "...        ...     ...     ...      ...      ...      ...      ...      ...   \n",
       "231233       0       0       0        0        0        0        0        0   \n",
       "231234       1       0       0        0        0        0        0        0   \n",
       "231235       0       0       1        0        0        0        0        0   \n",
       "231236       0       0       0        0        0        0        0        0   \n",
       "231237       0       0       0        0        0        0        0        0   \n",
       "\n",
       "        hour_15  hour_16  hour_17  hour_18  hour_19  hour_20  hour_21  \\\n",
       "0             0        0        0        0        0        0        0   \n",
       "1             0        0        0        0        0        0        0   \n",
       "2             0        0        0        0        0        0        0   \n",
       "3             0        0        0        0        0        0        0   \n",
       "4             0        0        0        0        0        0        0   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "231233        0        0        0        0        0        0        0   \n",
       "231234        0        0        0        0        0        0        0   \n",
       "231235        0        0        0        0        0        0        0   \n",
       "231236        0        0        0        0        0        0        0   \n",
       "231237        0        0        0        0        0        0        0   \n",
       "\n",
       "        hour_22  hour_23                             node_power_consumption  \\\n",
       "0             1        0  [7970 8450 8460 8470 7440 8470 8460 8470 7910 ...   \n",
       "1             1        0  [7970 8430 7940 8480 7460 8490 6890 8480 8480 ...   \n",
       "2             1        0  [7950 7970 8500 8480 8470 6900 8460 8450 8470 ...   \n",
       "3             0        1  [860 860 860 860 860 860 860 860 860 860 860 8...   \n",
       "4             0        1  [860 860 860 860 860 860 860 860 860 860 860 8...   \n",
       "...         ...      ...                                                ...   \n",
       "231233        0        0                                              [920]   \n",
       "231234        0        0  [870 860 860 860 860 870 860 870 860 860 860 8...   \n",
       "231235        0        0  [ 620  620  610  630  630  630  620  620  630 ...   \n",
       "231236        0        0                                              [860]   \n",
       "231237        0        0                                              [900]   \n",
       "\n",
       "                                    mem_power_consumption  \\\n",
       "0       [418 724 724 678 556 654 606 600 600 488 606 4...   \n",
       "1       [720 738 736 614 720 642 632 524 598 628 616 5...   \n",
       "2       [672 720 716 630 674 474 644 606 602 564 650 5...   \n",
       "3       [38 40 46 44 48 40 44 46 42 40 40 40 38 46 44 ...   \n",
       "4       [36 44 42 42 44 40 44 42 50 42 42 46 48 42 44 ...   \n",
       "...                                                   ...   \n",
       "231233                                               [36]   \n",
       "231234  [44 36 36 36 36 36 36 36 52 36 36 36 36 36 36 ...   \n",
       "231235  [38 40 38 38 38 42 38 38 40 38 38 38 38 38 40 ...   \n",
       "231236                                               [36]   \n",
       "231237                                               [36]   \n",
       "\n",
       "                                    cpu_power_consumption  \n",
       "0       [ 948 1628 1650 1544 1260 1532 1418 1700 1710 ...  \n",
       "1       [1640 1604 1592 1364 1532 1508 1528 1476 1674 ...  \n",
       "2       [1654 1600 1606 1438 1506 1108 1496 1670 1680 ...  \n",
       "3       [108 182 178 182 190 174 188 186 190 176 176 1...  \n",
       "4       [ 82 182 178 180 170 168 168 192 196 166 196 1...  \n",
       "...                                                   ...  \n",
       "231233                                               [90]  \n",
       "231234  [ 96  92 100  90  92  94  98  94  96  90  90  ...  \n",
       "231235  [282 202 246 234 274 288 274 288 250 252 284 2...  \n",
       "231236                                               [46]  \n",
       "231237                                               [58]  \n",
       "\n",
       "[231238 rows x 78 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.astype({col: int for col in df.select_dtypes(include='bool').columns})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1ed6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_columns = [\"node_power_consumption\", \"mem_power_consumption\", \"cpu_power_consumption\"]\n",
    "X_columns = [col for col in df.columns if col not in Y_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d629750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c727da9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>time_limit_scaled</th>\n",
       "      <th>num_nodes_req</th>\n",
       "      <th>has_req_nodes</th>\n",
       "      <th>num_cores_req</th>\n",
       "      <th>cores_per_task</th>\n",
       "      <th>num_tasks_final</th>\n",
       "      <th>num_gpus_req</th>\n",
       "      <th>mem_req</th>\n",
       "      <th>has_req_threads_per_core</th>\n",
       "      <th>is_shared_job</th>\n",
       "      <th>num_tasks_missing_or_inconsistent</th>\n",
       "      <th>partition_final</th>\n",
       "      <th>dow_0</th>\n",
       "      <th>dow_1</th>\n",
       "      <th>dow_2</th>\n",
       "      <th>dow_3</th>\n",
       "      <th>dow_4</th>\n",
       "      <th>dow_5</th>\n",
       "      <th>dow_6</th>\n",
       "      <th>dom_1</th>\n",
       "      <th>dom_2</th>\n",
       "      <th>dom_3</th>\n",
       "      <th>dom_4</th>\n",
       "      <th>dom_5</th>\n",
       "      <th>dom_6</th>\n",
       "      <th>dom_7</th>\n",
       "      <th>dom_8</th>\n",
       "      <th>dom_9</th>\n",
       "      <th>dom_10</th>\n",
       "      <th>dom_11</th>\n",
       "      <th>dom_12</th>\n",
       "      <th>dom_13</th>\n",
       "      <th>dom_14</th>\n",
       "      <th>dom_15</th>\n",
       "      <th>dom_16</th>\n",
       "      <th>dom_17</th>\n",
       "      <th>dom_18</th>\n",
       "      <th>dom_19</th>\n",
       "      <th>dom_20</th>\n",
       "      <th>dom_21</th>\n",
       "      <th>dom_22</th>\n",
       "      <th>dom_23</th>\n",
       "      <th>dom_24</th>\n",
       "      <th>dom_25</th>\n",
       "      <th>dom_26</th>\n",
       "      <th>dom_27</th>\n",
       "      <th>dom_28</th>\n",
       "      <th>dom_29</th>\n",
       "      <th>dom_30</th>\n",
       "      <th>dom_31</th>\n",
       "      <th>hour_0</th>\n",
       "      <th>hour_1</th>\n",
       "      <th>hour_2</th>\n",
       "      <th>hour_3</th>\n",
       "      <th>hour_4</th>\n",
       "      <th>hour_5</th>\n",
       "      <th>hour_6</th>\n",
       "      <th>hour_7</th>\n",
       "      <th>hour_8</th>\n",
       "      <th>hour_9</th>\n",
       "      <th>hour_10</th>\n",
       "      <th>hour_11</th>\n",
       "      <th>hour_12</th>\n",
       "      <th>hour_13</th>\n",
       "      <th>hour_14</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>node_power_consumption</th>\n",
       "      <th>mem_power_consumption</th>\n",
       "      <th>cpu_power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25200</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[7970 8450 8460 8470 7440 8470 8460 8470 7910 ...</td>\n",
       "      <td>[418 724 724 678 556 654 606 600 600 488 606 4...</td>\n",
       "      <td>[ 948 1628 1650 1544 1260 1532 1418 1700 1710 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25200</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[7970 8430 7940 8480 7460 8490 6890 8480 8480 ...</td>\n",
       "      <td>[720 738 736 614 720 642 632 524 598 628 616 5...</td>\n",
       "      <td>[1640 1604 1592 1364 1532 1508 1528 1476 1674 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25200</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[7950 7970 8500 8480 8470 6900 8460 8450 8470 ...</td>\n",
       "      <td>[672 720 716 630 674 474 644 606 602 564 650 5...</td>\n",
       "      <td>[1654 1600 1606 1438 1506 1108 1496 1670 1680 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25200</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[860 860 860 860 860 860 860 860 860 860 860 8...</td>\n",
       "      <td>[38 40 46 44 48 40 44 46 42 40 40 40 38 46 44 ...</td>\n",
       "      <td>[108 182 178 182 190 174 188 186 190 176 176 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25200</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[860 860 860 860 860 860 860 860 860 860 860 8...</td>\n",
       "      <td>[36 44 42 42 44 40 44 42 50 42 42 46 48 42 44 ...</td>\n",
       "      <td>[ 82 182 178 180 170 168 168 192 196 166 196 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_id  time_limit_scaled  num_nodes_req  has_req_nodes  num_cores_req  \\\n",
       "0     25200          -0.007838             16              0            256   \n",
       "1     25200          -0.007838             16              0            256   \n",
       "2     25200          -0.007838             16              0            256   \n",
       "3     25200          -1.243395              1              0             32   \n",
       "4     25200          -1.243395              1              0             32   \n",
       "\n",
       "   cores_per_task  num_tasks_final  num_gpus_req  mem_req  \\\n",
       "0               4               64            64      475   \n",
       "1               4               64            64      475   \n",
       "2               4               64            64      475   \n",
       "3              32                0             4       59   \n",
       "4              32                0             4       59   \n",
       "\n",
       "   has_req_threads_per_core  is_shared_job  num_tasks_missing_or_inconsistent  \\\n",
       "0                         0              0                                  0   \n",
       "1                         0              0                                  0   \n",
       "2                         0              0                                  0   \n",
       "3                         0              1                                  1   \n",
       "4                         0              1                                  1   \n",
       "\n",
       "   partition_final  dow_0  dow_1  dow_2  dow_3  dow_4  dow_5  dow_6  dom_1  \\\n",
       "0                1      0      0      0      0      0      0      1      0   \n",
       "1                1      0      0      0      0      0      0      1      0   \n",
       "2                1      0      0      0      0      0      0      1      0   \n",
       "3                1      0      0      0      0      0      0      1      0   \n",
       "4                1      0      0      0      0      0      0      1      0   \n",
       "\n",
       "   dom_2  dom_3  dom_4  dom_5  dom_6  dom_7  dom_8  dom_9  dom_10  dom_11  \\\n",
       "0      0      0      0      0      0      0      0      0       0       0   \n",
       "1      0      0      0      0      0      0      0      0       0       0   \n",
       "2      0      0      0      0      0      0      0      0       0       0   \n",
       "3      0      0      0      0      0      0      0      0       0       0   \n",
       "4      0      0      0      0      0      0      0      0       0       0   \n",
       "\n",
       "   dom_12  dom_13  dom_14  dom_15  dom_16  dom_17  dom_18  dom_19  dom_20  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   dom_21  dom_22  dom_23  dom_24  dom_25  dom_26  dom_27  dom_28  dom_29  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   dom_30  dom_31  hour_0  hour_1  hour_2  hour_3  hour_4  hour_5  hour_6  \\\n",
       "0       0       1       0       0       0       0       0       0       0   \n",
       "1       0       1       0       0       0       0       0       0       0   \n",
       "2       0       1       0       0       0       0       0       0       0   \n",
       "3       0       1       0       0       0       0       0       0       0   \n",
       "4       0       1       0       0       0       0       0       0       0   \n",
       "\n",
       "   hour_7  hour_8  hour_9  hour_10  hour_11  hour_12  hour_13  hour_14  \\\n",
       "0       0       0       0        0        0        0        0        0   \n",
       "1       0       0       0        0        0        0        0        0   \n",
       "2       0       0       0        0        0        0        0        0   \n",
       "3       0       0       0        0        0        0        0        0   \n",
       "4       0       0       0        0        0        0        0        0   \n",
       "\n",
       "   hour_15  hour_16  hour_17  hour_18  hour_19  hour_20  hour_21  hour_22  \\\n",
       "0        0        0        0        0        0        0        0        1   \n",
       "1        0        0        0        0        0        0        0        1   \n",
       "2        0        0        0        0        0        0        0        1   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   hour_23                             node_power_consumption  \\\n",
       "0        0  [7970 8450 8460 8470 7440 8470 8460 8470 7910 ...   \n",
       "1        0  [7970 8430 7940 8480 7460 8490 6890 8480 8480 ...   \n",
       "2        0  [7950 7970 8500 8480 8470 6900 8460 8450 8470 ...   \n",
       "3        1  [860 860 860 860 860 860 860 860 860 860 860 8...   \n",
       "4        1  [860 860 860 860 860 860 860 860 860 860 860 8...   \n",
       "\n",
       "                               mem_power_consumption  \\\n",
       "0  [418 724 724 678 556 654 606 600 600 488 606 4...   \n",
       "1  [720 738 736 614 720 642 632 524 598 628 616 5...   \n",
       "2  [672 720 716 630 674 474 644 606 602 564 650 5...   \n",
       "3  [38 40 46 44 48 40 44 46 42 40 40 40 38 46 44 ...   \n",
       "4  [36 44 42 42 44 40 44 42 50 42 42 46 48 42 44 ...   \n",
       "\n",
       "                               cpu_power_consumption  \n",
       "0  [ 948 1628 1650 1544 1260 1532 1418 1700 1710 ...  \n",
       "1  [1640 1604 1592 1364 1532 1508 1528 1476 1674 ...  \n",
       "2  [1654 1600 1606 1438 1506 1108 1496 1670 1680 ...  \n",
       "3  [108 182 178 182 190 174 188 186 190 176 176 1...  \n",
       "4  [ 82 182 178 180 170 168 168 192 196 166 196 1...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2216e917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing mean values for target variables (per instance)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaime\\AppData\\Local\\Temp\\ipykernel_6660\\1279088420.py:13: RuntimeWarning: Mean of empty slice.\n",
      "  return arr.mean()\n",
      "c:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\numpy\\_core\\_methods.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\Jaime\\AppData\\Local\\Temp\\ipykernel_6660\\1279088420.py:13: RuntimeWarning: Mean of empty slice.\n",
      "  return arr.mean()\n",
      "c:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\numpy\\_core\\_methods.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def compute_mean_per_instance(val):\n",
    "    \"\"\"\n",
    "    Convert a single instance's list/array to its mean value.\n",
    "    Example: [1, 4, 10] -> 5.0\n",
    "    \"\"\"\n",
    "    if isinstance(val, str):\n",
    "        # Remove brackets and split by whitespace\n",
    "        cleaned = val.strip('[]')\n",
    "        # Handle ellipsis (...) by removing it\n",
    "        cleaned = cleaned.replace('...', '')\n",
    "        # Split and convert to integers, filtering out empty strings\n",
    "        arr = np.array([int(x) for x in cleaned.split() if x])\n",
    "        return arr.mean()\n",
    "    elif isinstance(val, (list, np.ndarray)):\n",
    "        return np.array(val).mean()\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected type: {type(val)}\")\n",
    "\n",
    "# Compute mean for each instance in each target column\n",
    "print(\"Computing mean values for target variables (per instance)...\")\n",
    "for col in Y_columns:\n",
    "    # Apply the function to each row/instance\n",
    "    df[col + '_mean'] = df[col].apply(compute_mean_per_instance)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6b319ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final y shape: (231238, 3)\n",
      "Sample y values (first 5 rows):\n",
      "[[8318.88888889  588.77777778 1550.44444444]\n",
      " [8164.82758621  593.65517241 1556.48275862]\n",
      " [8193.11111111  599.77777778 1566.04444444]\n",
      " [ 630.37735849   42.45833333  177.75      ]\n",
      " [ 860.20833333   43.90243902  184.43902439]]\n"
     ]
    }
   ],
   "source": [
    "# Create new target column names\n",
    "Y_mean_columns = [col + '_mean' for col in Y_columns]\n",
    "\n",
    "# Extract y with mean values\n",
    "y = df[Y_mean_columns].values\n",
    "print(f\"Final y shape: {y.shape}\")\n",
    "print(f\"Sample y values (first 5 rows):\")\n",
    "print(y[:5])\n",
    "\n",
    "# Extract X\n",
    "X = df[X_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c727da9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>time_limit_scaled</th>\n",
       "      <th>num_nodes_req</th>\n",
       "      <th>has_req_nodes</th>\n",
       "      <th>num_cores_req</th>\n",
       "      <th>cores_per_task</th>\n",
       "      <th>num_tasks_final</th>\n",
       "      <th>num_gpus_req</th>\n",
       "      <th>mem_req</th>\n",
       "      <th>has_req_threads_per_core</th>\n",
       "      <th>is_shared_job</th>\n",
       "      <th>num_tasks_missing_or_inconsistent</th>\n",
       "      <th>partition_final</th>\n",
       "      <th>dow_0</th>\n",
       "      <th>dow_1</th>\n",
       "      <th>dow_2</th>\n",
       "      <th>dow_3</th>\n",
       "      <th>dow_4</th>\n",
       "      <th>dow_5</th>\n",
       "      <th>dow_6</th>\n",
       "      <th>dom_1</th>\n",
       "      <th>dom_2</th>\n",
       "      <th>dom_3</th>\n",
       "      <th>dom_4</th>\n",
       "      <th>dom_5</th>\n",
       "      <th>dom_6</th>\n",
       "      <th>dom_7</th>\n",
       "      <th>dom_8</th>\n",
       "      <th>dom_9</th>\n",
       "      <th>dom_10</th>\n",
       "      <th>dom_11</th>\n",
       "      <th>dom_12</th>\n",
       "      <th>dom_13</th>\n",
       "      <th>dom_14</th>\n",
       "      <th>dom_15</th>\n",
       "      <th>dom_16</th>\n",
       "      <th>dom_17</th>\n",
       "      <th>dom_18</th>\n",
       "      <th>dom_19</th>\n",
       "      <th>dom_20</th>\n",
       "      <th>dom_21</th>\n",
       "      <th>dom_22</th>\n",
       "      <th>dom_23</th>\n",
       "      <th>dom_24</th>\n",
       "      <th>dom_25</th>\n",
       "      <th>dom_26</th>\n",
       "      <th>dom_27</th>\n",
       "      <th>dom_28</th>\n",
       "      <th>dom_29</th>\n",
       "      <th>dom_30</th>\n",
       "      <th>dom_31</th>\n",
       "      <th>hour_0</th>\n",
       "      <th>hour_1</th>\n",
       "      <th>hour_2</th>\n",
       "      <th>hour_3</th>\n",
       "      <th>hour_4</th>\n",
       "      <th>hour_5</th>\n",
       "      <th>hour_6</th>\n",
       "      <th>hour_7</th>\n",
       "      <th>hour_8</th>\n",
       "      <th>hour_9</th>\n",
       "      <th>hour_10</th>\n",
       "      <th>hour_11</th>\n",
       "      <th>hour_12</th>\n",
       "      <th>hour_13</th>\n",
       "      <th>hour_14</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>node_power_consumption</th>\n",
       "      <th>mem_power_consumption</th>\n",
       "      <th>cpu_power_consumption</th>\n",
       "      <th>node_power_consumption_mean</th>\n",
       "      <th>mem_power_consumption_mean</th>\n",
       "      <th>cpu_power_consumption_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25200</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[7970 8450 8460 8470 7440 8470 8460 8470 7910 ...</td>\n",
       "      <td>[418 724 724 678 556 654 606 600 600 488 606 4...</td>\n",
       "      <td>[ 948 1628 1650 1544 1260 1532 1418 1700 1710 ...</td>\n",
       "      <td>8318.888889</td>\n",
       "      <td>588.777778</td>\n",
       "      <td>1550.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25200</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[7970 8430 7940 8480 7460 8490 6890 8480 8480 ...</td>\n",
       "      <td>[720 738 736 614 720 642 632 524 598 628 616 5...</td>\n",
       "      <td>[1640 1604 1592 1364 1532 1508 1528 1476 1674 ...</td>\n",
       "      <td>8164.827586</td>\n",
       "      <td>593.655172</td>\n",
       "      <td>1556.482759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25200</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[7950 7970 8500 8480 8470 6900 8460 8450 8470 ...</td>\n",
       "      <td>[672 720 716 630 674 474 644 606 602 564 650 5...</td>\n",
       "      <td>[1654 1600 1606 1438 1506 1108 1496 1670 1680 ...</td>\n",
       "      <td>8193.111111</td>\n",
       "      <td>599.777778</td>\n",
       "      <td>1566.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25200</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[860 860 860 860 860 860 860 860 860 860 860 8...</td>\n",
       "      <td>[38 40 46 44 48 40 44 46 42 40 40 40 38 46 44 ...</td>\n",
       "      <td>[108 182 178 182 190 174 188 186 190 176 176 1...</td>\n",
       "      <td>630.377358</td>\n",
       "      <td>42.458333</td>\n",
       "      <td>177.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25200</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[860 860 860 860 860 860 860 860 860 860 860 8...</td>\n",
       "      <td>[36 44 42 42 44 40 44 42 50 42 42 46 48 42 44 ...</td>\n",
       "      <td>[ 82 182 178 180 170 168 168 192 196 166 196 1...</td>\n",
       "      <td>860.208333</td>\n",
       "      <td>43.902439</td>\n",
       "      <td>184.439024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group_id  time_limit_scaled  num_nodes_req  has_req_nodes  num_cores_req  \\\n",
       "0     25200          -0.007838             16              0            256   \n",
       "1     25200          -0.007838             16              0            256   \n",
       "2     25200          -0.007838             16              0            256   \n",
       "3     25200          -1.243395              1              0             32   \n",
       "4     25200          -1.243395              1              0             32   \n",
       "\n",
       "   cores_per_task  num_tasks_final  num_gpus_req  mem_req  \\\n",
       "0               4               64            64      475   \n",
       "1               4               64            64      475   \n",
       "2               4               64            64      475   \n",
       "3              32                0             4       59   \n",
       "4              32                0             4       59   \n",
       "\n",
       "   has_req_threads_per_core  is_shared_job  num_tasks_missing_or_inconsistent  \\\n",
       "0                         0              0                                  0   \n",
       "1                         0              0                                  0   \n",
       "2                         0              0                                  0   \n",
       "3                         0              1                                  1   \n",
       "4                         0              1                                  1   \n",
       "\n",
       "   partition_final  dow_0  dow_1  dow_2  dow_3  dow_4  dow_5  dow_6  dom_1  \\\n",
       "0                1      0      0      0      0      0      0      1      0   \n",
       "1                1      0      0      0      0      0      0      1      0   \n",
       "2                1      0      0      0      0      0      0      1      0   \n",
       "3                1      0      0      0      0      0      0      1      0   \n",
       "4                1      0      0      0      0      0      0      1      0   \n",
       "\n",
       "   dom_2  dom_3  dom_4  dom_5  dom_6  dom_7  dom_8  dom_9  dom_10  dom_11  \\\n",
       "0      0      0      0      0      0      0      0      0       0       0   \n",
       "1      0      0      0      0      0      0      0      0       0       0   \n",
       "2      0      0      0      0      0      0      0      0       0       0   \n",
       "3      0      0      0      0      0      0      0      0       0       0   \n",
       "4      0      0      0      0      0      0      0      0       0       0   \n",
       "\n",
       "   dom_12  dom_13  dom_14  dom_15  dom_16  dom_17  dom_18  dom_19  dom_20  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   dom_21  dom_22  dom_23  dom_24  dom_25  dom_26  dom_27  dom_28  dom_29  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   dom_30  dom_31  hour_0  hour_1  hour_2  hour_3  hour_4  hour_5  hour_6  \\\n",
       "0       0       1       0       0       0       0       0       0       0   \n",
       "1       0       1       0       0       0       0       0       0       0   \n",
       "2       0       1       0       0       0       0       0       0       0   \n",
       "3       0       1       0       0       0       0       0       0       0   \n",
       "4       0       1       0       0       0       0       0       0       0   \n",
       "\n",
       "   hour_7  hour_8  hour_9  hour_10  hour_11  hour_12  hour_13  hour_14  \\\n",
       "0       0       0       0        0        0        0        0        0   \n",
       "1       0       0       0        0        0        0        0        0   \n",
       "2       0       0       0        0        0        0        0        0   \n",
       "3       0       0       0        0        0        0        0        0   \n",
       "4       0       0       0        0        0        0        0        0   \n",
       "\n",
       "   hour_15  hour_16  hour_17  hour_18  hour_19  hour_20  hour_21  hour_22  \\\n",
       "0        0        0        0        0        0        0        0        1   \n",
       "1        0        0        0        0        0        0        0        1   \n",
       "2        0        0        0        0        0        0        0        1   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   hour_23                             node_power_consumption  \\\n",
       "0        0  [7970 8450 8460 8470 7440 8470 8460 8470 7910 ...   \n",
       "1        0  [7970 8430 7940 8480 7460 8490 6890 8480 8480 ...   \n",
       "2        0  [7950 7970 8500 8480 8470 6900 8460 8450 8470 ...   \n",
       "3        1  [860 860 860 860 860 860 860 860 860 860 860 8...   \n",
       "4        1  [860 860 860 860 860 860 860 860 860 860 860 8...   \n",
       "\n",
       "                               mem_power_consumption  \\\n",
       "0  [418 724 724 678 556 654 606 600 600 488 606 4...   \n",
       "1  [720 738 736 614 720 642 632 524 598 628 616 5...   \n",
       "2  [672 720 716 630 674 474 644 606 602 564 650 5...   \n",
       "3  [38 40 46 44 48 40 44 46 42 40 40 40 38 46 44 ...   \n",
       "4  [36 44 42 42 44 40 44 42 50 42 42 46 48 42 44 ...   \n",
       "\n",
       "                               cpu_power_consumption  \\\n",
       "0  [ 948 1628 1650 1544 1260 1532 1418 1700 1710 ...   \n",
       "1  [1640 1604 1592 1364 1532 1508 1528 1476 1674 ...   \n",
       "2  [1654 1600 1606 1438 1506 1108 1496 1670 1680 ...   \n",
       "3  [108 182 178 182 190 174 188 186 190 176 176 1...   \n",
       "4  [ 82 182 178 180 170 168 168 192 196 166 196 1...   \n",
       "\n",
       "   node_power_consumption_mean  mem_power_consumption_mean  \\\n",
       "0                  8318.888889                  588.777778   \n",
       "1                  8164.827586                  593.655172   \n",
       "2                  8193.111111                  599.777778   \n",
       "3                   630.377358                   42.458333   \n",
       "4                   860.208333                   43.902439   \n",
       "\n",
       "   cpu_power_consumption_mean  \n",
       "0                 1550.444444  \n",
       "1                 1556.482759  \n",
       "2                 1566.044444  \n",
       "3                  177.750000  \n",
       "4                  184.439024  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c082e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE THE SPLITS\n",
    "\n",
    "X,y = df[X_columns], df[Y_mean_columns]\n",
    "\n",
    "### FOR CLASSIC MODELS\n",
    "\n",
    "# Assuming you have your data in X (features) and y (labels)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit only on train!\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "### FOR TORCH MODELS\n",
    "\n",
    "# Convert to tensors (on CPU)\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)  # Use float32 for regression\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 1028\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=0, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, num_workers=0, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ad2dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataset, r\"C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\train_dataset.pt\")\n",
    "torch.save(val_dataset, r\"C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\val_dataset.pt\")\n",
    "torch.save(test_dataset, r\"C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\test_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62a772fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches - Train: 158, Val: 34, Test: 34\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of batches - Train: {len(train_loader)}, Val: {len(val_loader)}, Test: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73d04a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./models/code_models/')\n",
    "\n",
    "#import sklearn_models\n",
    "#import torch_models\n",
    "#import training_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b006a97",
   "metadata": {},
   "source": [
    "# SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78398ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model = sklearn_models.get_random_forest()\n",
    "\n",
    "# rf_trainer = training_utils.SklearnTrainer(\n",
    "#     model=rf_model,\n",
    "#     model_name=\"RandomForest_Default\",\n",
    "#     project_name=\"Test\",\n",
    "#     entity=\"100451397-universidad-carlos-iii-de-madrid\" \n",
    "# )\n",
    "\n",
    "# rf_model, rf_metrics = rf_trainer.train(\n",
    "#     X_train_scaled, y_train,\n",
    "#     X_val_scaled, y_val,\n",
    "#     config= rf_model.get_params()\n",
    "# )\n",
    "\n",
    "# print(\"\\nValidation Metrics:\")\n",
    "# for key, value in rf_metrics.items():\n",
    "#     if 'val' in key:\n",
    "#         print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# test_metrics, test_predictions = training_utils.evaluate_model(\n",
    "#     rf_model, X_test_scaled, y_test, model_type=\"sklearn\"\n",
    "# )\n",
    "\n",
    "# print(\"\\nTest Set Metrics:\")\n",
    "# for key, value in test_metrics.items():\n",
    "#     print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d78abd",
   "metadata": {},
   "source": [
    "# TORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41115b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19f82ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'training_utils' from 'c:\\\\Users\\\\Jaime\\\\Documents\\\\GitHub\\\\DS-HPE\\\\models/code_models\\\\training_utils.py'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload modules to get the updated code\n",
    "import importlib\n",
    "importlib.reload(torch_models)\n",
    "importlib.reload(training_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83bf3cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in X_train_scaled: False\n",
      "NaN in y_train: True\n",
      "Max value in X_train_scaled: 28725.0\n",
      "Max value in y_train: nan\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN in training data\n",
    "print(f\"NaN in X_train_scaled: {np.isnan(X_train_scaled).any()}\")\n",
    "print(f\"NaN in y_train: {np.isnan(y_train).any()}\")\n",
    "print(f\"Max value in X_train_scaled: {np.max(np.abs(X_train_scaled))}\")\n",
    "print(f\"Max value in y_train: {np.max(np.abs(y_train))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83532ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN rows in y_train: 2000\n",
      "Shape of y_train: (161866, 3)\n",
      "\n",
      "NaN count per column:\n",
      "node_power_consumption_mean: 0 NaN values\n",
      "mem_power_consumption_mean: 2000 NaN values\n",
      "cpu_power_consumption_mean: 2000 NaN values\n",
      "\n",
      "NaN in original df[Y_mean_columns]:\n",
      "node_power_consumption_mean       0\n",
      "mem_power_consumption_mean     2867\n",
      "cpu_power_consumption_mean     2867\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find where NaN values are\n",
    "print(f\"Number of NaN rows in y_train: {np.isnan(y_train).any(axis=1).sum()}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"\\nNaN count per column:\")\n",
    "for i, col in enumerate(Y_mean_columns):\n",
    "    nan_count = np.isnan(y_train[:, i]).sum()\n",
    "    print(f\"{col}: {nan_count} NaN values\")\n",
    "    \n",
    "# Check original dataframe\n",
    "print(f\"\\nNaN in original df[Y_mean_columns]:\")\n",
    "print(df[Y_mean_columns].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed2dec01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 231238\n",
      "After removing NaN in targets: 228371\n",
      "Rows removed: 2867\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with NaN values in target variables\n",
    "print(f\"Original dataset size: {len(df)}\")\n",
    "df_clean = df.dropna(subset=Y_mean_columns)\n",
    "print(f\"After removing NaN in targets: {len(df_clean)}\")\n",
    "print(f\"Rows removed: {len(df) - len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df7da840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN in X_train_scaled: False\n",
      "NaN in y_train: False\n",
      "Training set size: (159859, 75)\n",
      "Number of batches - Train: 156, Val: 34, Test: 34\n"
     ]
    }
   ],
   "source": [
    "# Recreate splits with clean data\n",
    "X_clean, y_clean = df_clean[X_columns], df_clean[Y_mean_columns]\n",
    "\n",
    "# Split data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_clean, y_clean, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Verify no NaN\n",
    "print(f\"NaN in X_train_scaled: {np.isnan(X_train_scaled).any()}\")\n",
    "print(f\"NaN in y_train: {np.isnan(y_train).any()}\")\n",
    "print(f\"Training set size: {X_train_scaled.shape}\")\n",
    "\n",
    "# Create PyTorch datasets\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 1028\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"Number of batches - Train: {len(train_loader)}, Val: {len(val_loader)}, Test: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69a2eae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension: 75\n"
     ]
    }
   ],
   "source": [
    "# Update input dimension\n",
    "input_dim = X_train_scaled.shape[1]\n",
    "print(f\"Input dimension: {input_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0f14247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload modules to get the updated code\n",
    "# import importlib\n",
    "# importlib.reload(torch_models)\n",
    "# importlib.reload(training_utils)\n",
    "\n",
    "# Initialize Dense NN model\n",
    "# input_dim = X_train_scaled.shape[1]\n",
    "# dense_model = torch_models.DenseNN(\n",
    "#     input_dim=input_dim,\n",
    "#     hidden_dims=[256, 128, 64], \n",
    "#     output_dim=3,\n",
    "#     dropout=0.2\n",
    "# )\n",
    "\n",
    "# Initialize trainer\n",
    "# trainer = training_utils.PyTorchTrainer(\n",
    "#     model=dense_model,\n",
    "#     model_name=\"Dense_NN\",\n",
    "#     project_name=\"Test\",\n",
    "#     entity=\"100451397-universidad-carlos-iii-de-madrid\"\n",
    "# )\n",
    "\n",
    "\n",
    "# Train model\n",
    "# print(\"Starting training...\")\n",
    "# torch_model, torch_best_metrics = trainer.train(\n",
    "#     train_loader=train_loader,\n",
    "#     val_loader=val_loader,\n",
    "#     epochs=150,\n",
    "#     lr=0.001,  # You might want to adjust learning rate\n",
    "#     weight_decay=1e-5,\n",
    "#     patience=80,\n",
    "# )\n",
    "\n",
    "# print(\"\\nTraining completed!\")\n",
    "# print(\"\\nBest Validation Metrics:\")\n",
    "# for key, value in torch_best_metrics.items():\n",
    "#     if isinstance(value, (int, float)):\n",
    "#         print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# Evaluate and log test metrics to W&B\n",
    "# print(\"\\nEvaluating on test set...\")\n",
    "# test_metrics, test_predictions = trainer.evaluate_test_set(test_loader)\n",
    "\n",
    "# Save model\n",
    "# model_path = r'C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\models\\trained_models\\dense_nn_model.pt'\n",
    "# torch.save(torch_model.state_dict(), model_path)\n",
    "# print(f\"\\nModel saved to: {model_path}\")\n",
    "\n",
    "# Finish W&B run (moved after test evaluation)\n",
    "# import wandb\n",
    "# wandb.finish()\n",
    "# print(\"\\nW&B run finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f1ea86",
   "metadata": {},
   "source": [
    "# W&B Hyperparameter Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fc5473a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweep configuration created!\n",
      "Method: bayes\n",
      "Number of hidden_dims options: 6\n",
      "Dropout range: 0.1-0.5\n",
      "Learning rate range: 1e-05-0.01\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Define sweep configuration\n",
    "sweep_config = {\n",
    "    'method': 'bayes',  # Options: 'grid', 'random', 'bayes'\n",
    "    'metric': {\n",
    "        'name': 'val_loss',\n",
    "        'goal': 'minimize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'hidden_dims': {\n",
    "            'values': [\n",
    "                [512, 256, 128, 64, 32],\n",
    "                [256, 128, 64],\n",
    "                [512, 256, 128],\n",
    "                [1024, 512, 256, 128],\n",
    "                [384, 192, 96],\n",
    "                [768, 384, 192]\n",
    "            ]\n",
    "        },\n",
    "        'dropout': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 0.1,\n",
    "            'max': 0.5\n",
    "        },\n",
    "        'lr': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 0.00001,\n",
    "            'max': 0.01\n",
    "        },\n",
    "        'weight_decay': {\n",
    "            'values': [0, 1e-6, 1e-5, 1e-4]\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [512, 1028, 2048]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'value': 150  # Fixed value\n",
    "        },\n",
    "        'patience': {\n",
    "            'values': [50, 80, 100]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Sweep configuration created!\")\n",
    "print(f\"Method: {sweep_config['method']}\")\n",
    "print(f\"Number of hidden_dims options: {len(sweep_config['parameters']['hidden_dims']['values'])}\")\n",
    "print(f\"Dropout range: {sweep_config['parameters']['dropout']['min']}-{sweep_config['parameters']['dropout']['max']}\")\n",
    "print(f\"Learning rate range: {sweep_config['parameters']['lr']['min']}-{sweep_config['parameters']['lr']['max']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6017cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweep training function defined!\n"
     ]
    }
   ],
   "source": [
    "# Training function for sweep\n",
    "# Training function for sweep\n",
    "def train_sweep():\n",
    "    # Initialize wandb run with sweep\n",
    "    run = wandb.init()\n",
    "    config = wandb.config\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Starting sweep run with config:\")\n",
    "    print(f\"  Hidden dims: {config.hidden_dims}\")\n",
    "    print(f\"  Dropout: {config.dropout:.3f}\")\n",
    "    print(f\"  Learning rate: {config.lr:.6f}\")\n",
    "    print(f\"  Weight decay: {config.weight_decay}\")\n",
    "    print(f\"  Batch size: {config.batch_size}\")\n",
    "    print(f\"  Patience: {config.patience}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    # Create data loaders with sweep batch size\n",
    "    train_loader_sweep = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=True\n",
    "    )\n",
    "    val_loader_sweep = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Reload modules to ensure latest version\n",
    "    importlib.reload(torch_models)\n",
    "    importlib.reload(training_utils)\n",
    "    \n",
    "    # Create model with sweep parameters\n",
    "    model = torch_models.DenseNN(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dims=config.hidden_dims,\n",
    "        output_dim=3,\n",
    "        dropout=config.dropout\n",
    "    )\n",
    "    \n",
    "    # Create trainer (don't pass entity/project as wandb.init already did that)\n",
    "    trainer = training_utils.PyTorchTrainer(\n",
    "        model=model,\n",
    "        model_name=\"DenseNN_Sweep\",\n",
    "        project_name=None,  # Already initialized by wandb.init()\n",
    "        entity=None\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    try:\n",
    "        trained_model, metrics = trainer.train(\n",
    "            train_loader=train_loader_sweep,\n",
    "            val_loader=val_loader_sweep,\n",
    "            epochs=config.epochs,\n",
    "            lr=config.lr,\n",
    "            weight_decay=config.weight_decay,\n",
    "            patience=config.patience\n",
    "        )\n",
    "        \n",
    "        # Fix: Check if val_loss exists and is numeric before formatting\n",
    "        val_loss = metrics.get('val_loss', None)\n",
    "        if val_loss is not None and isinstance(val_loss, (int, float)):\n",
    "            print(f\"\\nRun completed! Best val_loss: {val_loss:.4f}\")\n",
    "        else:\n",
    "            print(f\"\\nRun completed! Best val_loss: {val_loss}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {e}\")\n",
    "        # Log error to wandb while run is still active\n",
    "        try:\n",
    "            wandb.log({\"error\": str(e)})\n",
    "        except:\n",
    "            pass  # If wandb.log fails, just continue\n",
    "    \n",
    "    # Run is automatically finished by wandb.agent\n",
    "\n",
    "print(\"Sweep training function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9db3ff7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 6h6h4pkr\n",
      "Sweep URL: https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/sweeps/6h6h4pkr\n",
      "Sweep created with ID: 6h6h4pkr\n",
      "View sweep at: https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/sweeps/6h6h4pkr\n"
     ]
    }
   ],
   "source": [
    "# Initialize sweep\n",
    "sweep_id = wandb.sweep(\n",
    "    sweep_config, \n",
    "    project=\"Test\",\n",
    "    entity=\"100451397-universidad-carlos-iii-de-madrid\"\n",
    ")\n",
    "\n",
    "print(f\"Sweep created with ID: {sweep_id}\")\n",
    "print(f\"View sweep at: https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/sweeps/{sweep_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07e6c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sweep agent...\n",
      "This will run multiple training runs with different hyperparameter combinations\n",
      "You can stop it anytime with Kernel -> Interrupt\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: y9zz0gly with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.48074127686692814\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 150\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dims: [384, 192, 96]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.004298805563210925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-06\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m100451397\u001b[0m (\u001b[33m100451397-universidad-carlos-iii-de-madrid\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\wandb\\run-20251216_125048-y9zz0gly</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/y9zz0gly' target=\"_blank\">light-sweep-1</a></strong> to <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/sweeps/wwjbagun' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/sweeps/wwjbagun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/sweeps/wwjbagun' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/sweeps/wwjbagun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/y9zz0gly' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/y9zz0gly</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting sweep run with config:\n",
      "  Hidden dims: [384, 192, 96]\n",
      "  Dropout: 0.481\n",
      "  Learning rate: 0.004299\n",
      "  Weight decay: 1e-06\n",
      "  Batch size: 512\n",
      "  Patience: 50\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">light-sweep-1</strong> at: <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/y9zz0gly' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/y9zz0gly</a><br> View project at: <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251216_125048-y9zz0gly\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\wandb\\run-20251216_125051-y9zz0gly</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/y9zz0gly' target=\"_blank\">DenseNN_Sweep</a></strong> to <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/sweeps/wwjbagun' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/sweeps/wwjbagun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/sweeps/wwjbagun' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/sweeps/wwjbagun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/y9zz0gly' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/y9zz0gly</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\triton\\knobs.py:212: UserWarning: Failed to find cuobjdump.exe\n",
      "  warnings.warn(f\"Failed to find {binary}\")\n",
      "c:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\triton\\knobs.py:212: UserWarning: Failed to find nvdisasm.exe\n",
      "  warnings.warn(f\"Failed to find {binary}\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "# Run sweep agent\n",
    "# count = number of runs to execute\n",
    "# You can run this multiple times or in parallel from different machines/terminals\n",
    "\n",
    "\"\"\"print(\"Starting sweep agent...\")\n",
    "print(\"This will run multiple training runs with different hyperparameter combinations\")\n",
    "print(\"You can stop it anytime with Kernel -> Interrupt\\n\")\n",
    "\n",
    "wandb.agent(\n",
    "    sweep_id, \n",
    "    train_sweep, \n",
    "    count=20  # Number of runs to try (adjust as needed)\n",
    ")\n",
    "\n",
    "print(\"\\n\\nSweep completed!\")\n",
    "print(f\"View results at: https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/sweeps/{sweep_id}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "311a54a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m100451397\u001b[0m (\u001b[33m100451397-universidad-carlos-iii-de-madrid\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\wandb\\run-20251218_145547-26ionlkw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/26ionlkw' target=\"_blank\">Manual_manual_test_512-256-128</a></strong> to <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/26ionlkw' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/26ionlkw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data loaders ready:\n",
      "  Training: 156 batches\n",
      "  Validation: 34 batches\n",
      "  Test: 34 batches\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_config = {\n",
    "    'hidden_dims': [512, 256, 128],  # List of hidden layer sizes\n",
    "    'dropout': 0.15559998021833732,                          # Dropout rate (0.0 - 0.5)\n",
    "    'lr': 0.0009719478103336032,                             # Learning rate\n",
    "    'weight_decay': 0.00001,                    # L2 regularization strength\n",
    "    'batch_size': 1028,                      # Batch size for training\n",
    "    'epochs': 150,                           # Maximum number of epochs\n",
    "    'patience': 80                           # Early stopping patience\n",
    "}\n",
    "\n",
    "config_name = \"manual_test\"\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(\n",
    "    project=\"Test\",\n",
    "    entity=\"100451397-universidad-carlos-iii-de-madrid\",\n",
    "    name=f\"Manual_{config_name}_{'-'.join(map(str, test_config['hidden_dims']))}\",\n",
    "    config=test_config,\n",
    "    tags=[\"manual_test\", config_name]\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader_test = DataLoader(train_dataset, batch_size=test_config['batch_size'], shuffle=True)\n",
    "val_loader_test = DataLoader(val_dataset, batch_size=test_config['batch_size'], shuffle=False)\n",
    "test_loader_test = DataLoader(test_dataset, batch_size=test_config['batch_size'], shuffle=False)\n",
    "\n",
    "print(f\"\\nData loaders ready:\")\n",
    "print(f\"  Training: {len(train_loader_test)} batches\")\n",
    "print(f\"  Validation: {len(val_loader_test)} batches\")\n",
    "print(f\"  Test: {len(test_loader_test)} batches\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6491f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\wandb\\run-20251218_151011-dutij2lm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/dutij2lm' target=\"_blank\">Manual_manual_test_512-256-128</a></strong> to <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/dutij2lm' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/dutij2lm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created: 205,315 parameters\n",
      "\n",
      "================================================================================\n",
      "STARTING TRAINING\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Manual_manual_test_512-256-128</strong> at: <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/dutij2lm' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/dutij2lm</a><br> View project at: <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251218_151011-dutij2lm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\wandb\\run-20251218_151012-j5xtjhrh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/j5xtjhrh' target=\"_blank\">DenseNN_manual_test</a></strong> to <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/j5xtjhrh' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/j5xtjhrh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reload modules\n",
    "importlib.reload(torch_models)\n",
    "importlib.reload(training_utils)\n",
    "\n",
    "# Ensure wandb is initialized (reinitialize if needed)\n",
    "if not wandb.run:\n",
    "    wandb.init(\n",
    "        project=\"Test\",\n",
    "        entity=\"100451397-universidad-carlos-iii-de-madrid\",\n",
    "        name=f\"Manual_{config_name}_{'-'.join(map(str, test_config['hidden_dims']))}\",\n",
    "        config=test_config,\n",
    "        tags=[\"manual_test\", config_name]\n",
    "    )\n",
    "\n",
    "# Create model\n",
    "test_model = torch_models.DenseNN(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dims=test_config['hidden_dims'],\n",
    "    output_dim=3,\n",
    "    dropout=test_config['dropout']\n",
    ")\n",
    "\n",
    "n_params = sum(p.numel() for p in test_model.parameters())\n",
    "print(f\"Model created: {n_params:,} parameters\")\n",
    "\n",
    "# Create trainer\n",
    "test_trainer = training_utils.PyTorchTrainer(\n",
    "    model=test_model,\n",
    "    model_name=f\"DenseNN_{config_name}\",\n",
    "    project_name=None,\n",
    "    entity=None\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "trained_model, metrics = test_trainer.train(\n",
    "    train_loader=train_loader_test,\n",
    "    val_loader=val_loader_test,\n",
    "    epochs=test_config['epochs'],\n",
    "    lr=test_config['lr'],\n",
    "    weight_decay=test_config['weight_decay'],\n",
    "    patience=test_config['patience']\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nBest Validation Metrics:\")\n",
    "for key, value in metrics.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST SET EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_metrics, test_predictions = test_trainer.evaluate_test_set(test_loader_test)\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "for key, value in test_metrics.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# Save model\n",
    "model_filename = f\"dense_nn_{config_name}_{'_'.join(map(str, test_config['hidden_dims']))}.pt\"\n",
    "model_path = f\"C:\\\\Users\\\\Jaime\\\\Documents\\\\GitHub\\\\DS-HPE\\\\models\\\\trained_models\\\\{model_filename}\"\n",
    "torch.save(trained_model.state_dict(), model_path)\n",
    "\n",
    "print(f\"\\nModel saved: {model_filename}\")\n",
    "\n",
    "# Finish\n",
    "wandb.finish()\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268fb16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(siple_mlp_model.state_dict(), r'C:\\Users\\iqbal\\Desktop\\4º Carrera\\Proyecto En DS\\DS-HPE\\models\\trained_models\\model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dae09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\wandb\\run-20251218_162359-ur45ntez</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/ur45ntez' target=\"_blank\">TrainTest_best_model_train_and_test_512-256-128</a></strong> to <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/ur45ntez' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/ur45ntez</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING AND TEST EVALUATION\n",
      "================================================================================\n",
      "\n",
      "Model created: 205,315 parameters\n",
      "Architecture: [512, 256, 128]\n",
      "\n",
      "================================================================================\n",
      "TRAINING\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">TrainTest_best_model_train_and_test_512-256-128</strong> at: <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/ur45ntez' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/ur45ntez</a><br> View project at: <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251218_162359-ur45ntez\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\wandb\\run-20251218_162400-mnfu6fkj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/mnfu6fkj' target=\"_blank\">DenseNN_best_model_train_and_test</a></strong> to <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/mnfu6fkj' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/mnfu6fkj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\triton\\knobs.py:212: UserWarning: Failed to find cuobjdump.exe\n",
      "  warnings.warn(f\"Failed to find {binary}\")\n",
      "c:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\triton\\knobs.py:212: UserWarning: Failed to find nvdisasm.exe\n",
      "  warnings.warn(f\"Failed to find {binary}\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>████████████████▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>████▇▆▆▅▅▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_rmse</td><td>███▇▇▆▆▆▅▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▆▆▅▅▅▅▄▃▃▁▂▂▂▂▁▂▂▂▂▂▁▂▂▂▁▁▁▂▂▂▁▃▁▁▂▂▂</td></tr><tr><td>val_mae_max_power</td><td>▅▄▃▄▇█▇▇▇▅▃▃▂▃▂▁▁▁▂▁▂▂▂▂▂▂▂▂▃▂▃▂▂▂▂▂▂▂▂▂</td></tr><tr><td>val_mae_mean_power</td><td>██▆▅▅▇▇▆▆▆▆▄▃▂▄▂▃▃▁▂▂▃▃▃▃▃▃▂▃▂▃▃▃▃▃▄▁▃▃▃</td></tr><tr><td>val_mae_min_power</td><td>▅▄▃▆██▇▇▆▂▂▁▂▁▂▂▂▁▂▂▂▂▃▂▂▁▁▂▃▂▂▂▂▂▃▂▂▂▂▂</td></tr><tr><td>val_r2_max_power</td><td>▁▃▃▄▄▅▆▆▆▆▆▆▇▇▇█▇▇▇█▇▇▇▇▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_r2_mean_power</td><td>▁▁▁▂▃▃▄▄▄▆▆▇▇▇██▇█▇▇██▇▇▇▇█▇▇▇▇█▇▇▇▇▇▇▇▇</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>133</td></tr><tr><td>best_val_loss</td><td>8499506.14706</td></tr><tr><td>best_val_rmse</td><td>2915.39125</td></tr><tr><td>epoch</td><td>149</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>train_loss</td><td>2828796.31731</td></tr><tr><td>train_rmse</td><td>1681.90259</td></tr><tr><td>val_loss</td><td>11404774.54412</td></tr><tr><td>val_mae_max_power</td><td>301.03644</td></tr><tr><td>val_mae_mean_power</td><td>1572.1908</td></tr><tr><td>+8</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">DenseNN_best_model_train_and_test</strong> at: <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/mnfu6fkj' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/mnfu6fkj</a><br> View project at: <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251218_162400-mnfu6fkj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Validation Metrics:\n",
      "  best_val_loss: 8499506.1471\n",
      "\n",
      "================================================================================\n",
      "COMPUTING TEST METRICS\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "You must call wandb.init() before wandb.log()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mError\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 80\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCOMPUTING TEST METRICS\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     78\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m test_metrics, test_predictions = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate_test_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader_best\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[32m     83\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m80\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\models/code_models\\training_utils.py:322\u001b[39m, in \u001b[36mPyTorchTrainer.evaluate_test_set\u001b[39m\u001b[34m(self, test_loader)\u001b[39m\n\u001b[32m    319\u001b[39m test_metrics[\u001b[33m'\u001b[39m\u001b[33mtest/r2_mean\u001b[39m\u001b[33m'\u001b[39m] = np.mean([test_metrics[\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtest/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_r2\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mnode\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmem\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m]])\n\u001b[32m    321\u001b[39m \u001b[38;5;66;03m# Log to W&B\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mwandb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_metrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m50\u001b[39m)\n\u001b[32m    325\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTEST SET EVALUATION\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\wandb\\sdk\\lib\\preinit.py:36\u001b[39m, in \u001b[36mPreInitCallable.<locals>.preinit_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpreinit_wrapper\u001b[39m(*args: Any, **kwargs: Any) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m wandb.Error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mYou must call wandb.init() before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m()\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mError\u001b[39m: You must call wandb.init() before wandb.log()"
     ]
    }
   ],
   "source": [
    "# Configuration for the best model (manually insert your best hyperparameters)\n",
    "best_config = {\n",
    "    'hidden_dims': [512, 256, 128],      # Your best architecture\n",
    "    'dropout': 0.15559998021833732,      # Your best dropout\n",
    "    'lr': 0.0009719478103336032,         # Learning rate\n",
    "    'weight_decay': 0.00001,             # Weight decay\n",
    "    'batch_size': 1028,                  # Batch size\n",
    "    'epochs': 150,                       # Training epochs\n",
    "    'patience': 80                       # Early stopping patience\n",
    "}\n",
    "\n",
    "config_name = \"best_model_train_and_test\"\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(\n",
    "    project=\"Test\",\n",
    "    entity=\"100451397-universidad-carlos-iii-de-madrid\",\n",
    "    name=f\"TrainTest_{config_name}_{'-'.join(map(str, best_config['hidden_dims']))}\",\n",
    "    config=best_config,\n",
    "    tags=[\"train_and_test\", config_name]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING AND TEST EVALUATION\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Create data loaders with best batch size\n",
    "train_loader_best = DataLoader(train_dataset, batch_size=best_config['batch_size'], shuffle=True)\n",
    "val_loader_best = DataLoader(val_dataset, batch_size=best_config['batch_size'], shuffle=False)\n",
    "test_loader_best = DataLoader(test_dataset, batch_size=best_config['batch_size'], shuffle=False)\n",
    "\n",
    "# Reload modules\n",
    "importlib.reload(torch_models)\n",
    "importlib.reload(training_utils)\n",
    "\n",
    "# Create model with best architecture\n",
    "test_model = torch_models.DenseNN(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dims=best_config['hidden_dims'],\n",
    "    output_dim=3,\n",
    "    dropout=best_config['dropout']\n",
    ")\n",
    "\n",
    "n_params = sum(p.numel() for p in test_model.parameters())\n",
    "print(f\"Model created: {n_params:,} parameters\")\n",
    "print(f\"Architecture: {best_config['hidden_dims']}\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = training_utils.PyTorchTrainer(\n",
    "    model=test_model,\n",
    "    model_name=f\"DenseNN_{config_name}\",\n",
    "    project_name=None,  # Already initialized\n",
    "    entity=None\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "trained_model, metrics = trainer.train(\n",
    "    train_loader=train_loader_best,\n",
    "    val_loader=val_loader_best,\n",
    "    epochs=best_config['epochs'],\n",
    "    lr=best_config['lr'],\n",
    "    weight_decay=best_config['weight_decay'],\n",
    "    patience=best_config['patience']\n",
    ")\n",
    "\n",
    "print(\"\\nBest Validation Metrics:\")\n",
    "for key, value in metrics.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPUTING TEST METRICS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Ensure wandb is still active\n",
    "if not wandb.run:\n",
    "    print(\"WARNING: W&B run was closed. Reinitializing...\")\n",
    "    wandb.init(\n",
    "        project=\"Test\",\n",
    "        entity=\"100451397-universidad-carlos-iii-de-madrid\",\n",
    "        name=f\"TrainTest_{config_name}_{'-'.join(map(str, best_config['hidden_dims']))}_resumed\",\n",
    "        config=best_config,\n",
    "        tags=[\"train_and_test\", config_name, \"resumed\"]\n",
    "    )\n",
    "\n",
    "test_metrics, test_predictions = trainer.evaluate_test_set(test_loader_best)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(f\"  MSE:  {test_metrics['mse']:.4f}\")\n",
    "print(f\"  RMSE: {test_metrics['rmse']:.4f}\")\n",
    "print(f\"  MAE:  {test_metrics['mae']:.4f}\")\n",
    "print(f\"  R²:   {test_metrics['r2']:.4f}\")\n",
    "\n",
    "# Optional: Display per-output metrics if available\n",
    "if 'mse_per_output' in test_metrics:\n",
    "    output_names = ['node_power', 'mem_power', 'cpu_power']\n",
    "    print(\"\\nPer-Output Metrics:\")\n",
    "    for i, name in enumerate(output_names):\n",
    "        print(f\"\\n  {name}:\")\n",
    "        print(f\"    MSE:  {test_metrics['mse_per_output'][i]:.4f}\")\n",
    "        print(f\"    RMSE: {test_metrics['rmse_per_output'][i]:.4f}\")\n",
    "        print(f\"    MAE:  {test_metrics['mae_per_output'][i]:.4f}\")\n",
    "        print(f\"    R²:   {test_metrics['r2_per_output'][i]:.4f}\")\n",
    "\n",
    "# Finish W&B run\n",
    "wandb.finish()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING AND TEST EVALUATION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
