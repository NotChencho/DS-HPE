{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2228800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e187a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "data_path = r\"C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\final_dataset.csv\"\n",
    "data_target = r\"C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\data_to_train_meantime.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc1dc12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jaime\\AppData\\Local\\Temp\\ipykernel_20600\\1654078941.py:3: DtypeWarning: Columns (17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n"
     ]
    }
   ],
   "source": [
    "# LOAD THE ESSENTIALS\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "df_targets = pd.read_csv(data_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea940766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>group_id</th>\n",
       "      <th>group_major</th>\n",
       "      <th>submit_time</th>\n",
       "      <th>time_limit_cat</th>\n",
       "      <th>time_limit_scaled</th>\n",
       "      <th>num_nodes_req</th>\n",
       "      <th>has_req_nodes</th>\n",
       "      <th>num_cores_req</th>\n",
       "      <th>cores_per_task</th>\n",
       "      <th>num_tasks_final</th>\n",
       "      <th>num_gpus_req</th>\n",
       "      <th>mem_req</th>\n",
       "      <th>has_req_threads_per_core</th>\n",
       "      <th>is_shared_job</th>\n",
       "      <th>num_tasks_missing_or_inconsistent</th>\n",
       "      <th>partition_final</th>\n",
       "      <th>qos_final</th>\n",
       "      <th>dow_0</th>\n",
       "      <th>dow_1</th>\n",
       "      <th>dow_2</th>\n",
       "      <th>dow_3</th>\n",
       "      <th>dow_4</th>\n",
       "      <th>dow_5</th>\n",
       "      <th>dow_6</th>\n",
       "      <th>dom_1</th>\n",
       "      <th>dom_2</th>\n",
       "      <th>dom_3</th>\n",
       "      <th>dom_4</th>\n",
       "      <th>dom_5</th>\n",
       "      <th>dom_6</th>\n",
       "      <th>dom_7</th>\n",
       "      <th>dom_8</th>\n",
       "      <th>dom_9</th>\n",
       "      <th>dom_10</th>\n",
       "      <th>dom_11</th>\n",
       "      <th>dom_12</th>\n",
       "      <th>dom_13</th>\n",
       "      <th>dom_14</th>\n",
       "      <th>dom_15</th>\n",
       "      <th>dom_16</th>\n",
       "      <th>dom_17</th>\n",
       "      <th>dom_18</th>\n",
       "      <th>dom_19</th>\n",
       "      <th>dom_20</th>\n",
       "      <th>dom_21</th>\n",
       "      <th>dom_22</th>\n",
       "      <th>dom_23</th>\n",
       "      <th>dom_24</th>\n",
       "      <th>dom_25</th>\n",
       "      <th>dom_26</th>\n",
       "      <th>dom_27</th>\n",
       "      <th>dom_28</th>\n",
       "      <th>dom_29</th>\n",
       "      <th>dom_30</th>\n",
       "      <th>dom_31</th>\n",
       "      <th>hour_0</th>\n",
       "      <th>hour_1</th>\n",
       "      <th>hour_2</th>\n",
       "      <th>hour_3</th>\n",
       "      <th>hour_4</th>\n",
       "      <th>hour_5</th>\n",
       "      <th>hour_6</th>\n",
       "      <th>hour_7</th>\n",
       "      <th>hour_8</th>\n",
       "      <th>hour_9</th>\n",
       "      <th>hour_10</th>\n",
       "      <th>hour_11</th>\n",
       "      <th>hour_12</th>\n",
       "      <th>hour_13</th>\n",
       "      <th>hour_14</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>node_power_consumption</th>\n",
       "      <th>mem_power_consumption</th>\n",
       "      <th>cpu_power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25200</td>\n",
       "      <td>main</td>\n",
       "      <td>2020-05-31 22:09:29+00:00</td>\n",
       "      <td>medium (1–5h)</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[7970 8450 8460 8470 7440 8470 8460 8470 7910 ...</td>\n",
       "      <td>[418 724 724 678 556 654 606 600 600 488 606 4...</td>\n",
       "      <td>[ 948 1628 1650 1544 1260 1532 1418 1700 1710 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25200</td>\n",
       "      <td>main</td>\n",
       "      <td>2020-05-31 22:22:08+00:00</td>\n",
       "      <td>medium (1–5h)</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[7970 8430 7940 8480 7460 8490 6890 8480 8480 ...</td>\n",
       "      <td>[720 738 736 614 720 642 632 524 598 628 616 5...</td>\n",
       "      <td>[1640 1604 1592 1364 1532 1508 1528 1476 1674 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>25200</td>\n",
       "      <td>main</td>\n",
       "      <td>2020-05-31 22:41:38+00:00</td>\n",
       "      <td>medium (1–5h)</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[7950 7970 8500 8480 8470 6900 8460 8450 8470 ...</td>\n",
       "      <td>[672 720 716 630 674 474 644 606 602 564 650 5...</td>\n",
       "      <td>[1654 1600 1606 1438 1506 1108 1496 1670 1680 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>25200</td>\n",
       "      <td>main</td>\n",
       "      <td>2020-05-31 23:26:23+00:00</td>\n",
       "      <td>short (&lt;1h)</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[860 860 860 860 860 860 860 860 860 860 860 8...</td>\n",
       "      <td>[38 40 46 44 48 40 44 46 42 40 40 40 38 46 44 ...</td>\n",
       "      <td>[108 182 178 182 190 174 188 186 190 176 176 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>25200</td>\n",
       "      <td>main</td>\n",
       "      <td>2020-05-31 23:08:01+00:00</td>\n",
       "      <td>short (&lt;1h)</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>[860 860 860 860 860 860 860 860 860 860 860 8...</td>\n",
       "      <td>[36 44 42 42 44 40 44 42 50 42 42 46 48 42 44 ...</td>\n",
       "      <td>[ 82 182 178 180 170 168 168 192 196 166 196 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  group_id group_major                submit_time time_limit_cat  \\\n",
       "0           0     25200        main  2020-05-31 22:09:29+00:00  medium (1–5h)   \n",
       "1           1     25200        main  2020-05-31 22:22:08+00:00  medium (1–5h)   \n",
       "2           2     25200        main  2020-05-31 22:41:38+00:00  medium (1–5h)   \n",
       "3           3     25200        main  2020-05-31 23:26:23+00:00    short (<1h)   \n",
       "4           4     25200        main  2020-05-31 23:08:01+00:00    short (<1h)   \n",
       "\n",
       "   time_limit_scaled  num_nodes_req  has_req_nodes  num_cores_req  \\\n",
       "0          -0.007838             16              0            256   \n",
       "1          -0.007838             16              0            256   \n",
       "2          -0.007838             16              0            256   \n",
       "3          -1.243395              1              0             32   \n",
       "4          -1.243395              1              0             32   \n",
       "\n",
       "   cores_per_task  num_tasks_final  num_gpus_req  mem_req  \\\n",
       "0               4               64            64      475   \n",
       "1               4               64            64      475   \n",
       "2               4               64            64      475   \n",
       "3              32                0             4       59   \n",
       "4              32                0             4       59   \n",
       "\n",
       "   has_req_threads_per_core  is_shared_job  num_tasks_missing_or_inconsistent  \\\n",
       "0                         0              0                              False   \n",
       "1                         0              0                              False   \n",
       "2                         0              0                              False   \n",
       "3                         0              1                               True   \n",
       "4                         0              1                               True   \n",
       "\n",
       "   partition_final qos_final  dow_0  dow_1  dow_2  dow_3  dow_4  dow_5  dow_6  \\\n",
       "0                1         1  False  False  False  False  False  False   True   \n",
       "1                1         1  False  False  False  False  False  False   True   \n",
       "2                1         1  False  False  False  False  False  False   True   \n",
       "3                1         1  False  False  False  False  False  False   True   \n",
       "4                1         1  False  False  False  False  False  False   True   \n",
       "\n",
       "   dom_1  dom_2  dom_3  dom_4  dom_5  dom_6  dom_7  dom_8  dom_9  dom_10  \\\n",
       "0  False  False  False  False  False  False  False  False  False   False   \n",
       "1  False  False  False  False  False  False  False  False  False   False   \n",
       "2  False  False  False  False  False  False  False  False  False   False   \n",
       "3  False  False  False  False  False  False  False  False  False   False   \n",
       "4  False  False  False  False  False  False  False  False  False   False   \n",
       "\n",
       "   dom_11  dom_12  dom_13  dom_14  dom_15  dom_16  dom_17  dom_18  dom_19  \\\n",
       "0   False   False   False   False   False   False   False   False   False   \n",
       "1   False   False   False   False   False   False   False   False   False   \n",
       "2   False   False   False   False   False   False   False   False   False   \n",
       "3   False   False   False   False   False   False   False   False   False   \n",
       "4   False   False   False   False   False   False   False   False   False   \n",
       "\n",
       "   dom_20  dom_21  dom_22  dom_23  dom_24  dom_25  dom_26  dom_27  dom_28  \\\n",
       "0   False   False   False   False   False   False   False   False   False   \n",
       "1   False   False   False   False   False   False   False   False   False   \n",
       "2   False   False   False   False   False   False   False   False   False   \n",
       "3   False   False   False   False   False   False   False   False   False   \n",
       "4   False   False   False   False   False   False   False   False   False   \n",
       "\n",
       "   dom_29  dom_30  dom_31  hour_0  hour_1  hour_2  hour_3  hour_4  hour_5  \\\n",
       "0   False   False    True   False   False   False   False   False   False   \n",
       "1   False   False    True   False   False   False   False   False   False   \n",
       "2   False   False    True   False   False   False   False   False   False   \n",
       "3   False   False    True   False   False   False   False   False   False   \n",
       "4   False   False    True   False   False   False   False   False   False   \n",
       "\n",
       "   hour_6  hour_7  hour_8  hour_9  hour_10  hour_11  hour_12  hour_13  \\\n",
       "0   False   False   False   False    False    False    False    False   \n",
       "1   False   False   False   False    False    False    False    False   \n",
       "2   False   False   False   False    False    False    False    False   \n",
       "3   False   False   False   False    False    False    False    False   \n",
       "4   False   False   False   False    False    False    False    False   \n",
       "\n",
       "   hour_14  hour_15  hour_16  hour_17  hour_18  hour_19  hour_20  hour_21  \\\n",
       "0    False    False    False    False    False    False    False    False   \n",
       "1    False    False    False    False    False    False    False    False   \n",
       "2    False    False    False    False    False    False    False    False   \n",
       "3    False    False    False    False    False    False    False    False   \n",
       "4    False    False    False    False    False    False    False    False   \n",
       "\n",
       "   hour_22  hour_23                             node_power_consumption  \\\n",
       "0     True    False  [7970 8450 8460 8470 7440 8470 8460 8470 7910 ...   \n",
       "1     True    False  [7970 8430 7940 8480 7460 8490 6890 8480 8480 ...   \n",
       "2     True    False  [7950 7970 8500 8480 8470 6900 8460 8450 8470 ...   \n",
       "3    False     True  [860 860 860 860 860 860 860 860 860 860 860 8...   \n",
       "4    False     True  [860 860 860 860 860 860 860 860 860 860 860 8...   \n",
       "\n",
       "                               mem_power_consumption  \\\n",
       "0  [418 724 724 678 556 654 606 600 600 488 606 4...   \n",
       "1  [720 738 736 614 720 642 632 524 598 628 616 5...   \n",
       "2  [672 720 716 630 674 474 644 606 602 564 650 5...   \n",
       "3  [38 40 46 44 48 40 44 46 42 40 40 40 38 46 44 ...   \n",
       "4  [36 44 42 42 44 40 44 42 50 42 42 46 48 42 44 ...   \n",
       "\n",
       "                               cpu_power_consumption  \n",
       "0  [ 948 1628 1650 1544 1260 1532 1418 1700 1710 ...  \n",
       "1  [1640 1604 1592 1364 1532 1508 1528 1476 1674 ...  \n",
       "2  [1654 1600 1606 1438 1506 1108 1496 1670 1680 ...  \n",
       "3  [108 182 178 182 190 174 188 186 190 176 176 1...  \n",
       "4  [ 82 182 178 180 170 168 168 192 196 166 196 1...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff6621c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Unnamed: 0\",\"qos_final\",\"submit_time\", \"time_limit_cat\", \"group_major\",\"node_power_consumption\",\"mem_power_consumption\",\"cpu_power_consumption\"])\n",
    "df[[\"job_mean_power_consumption\",\"job_min_power_consumption\",\"job_max_power_consumption\"]] = df_targets[[\"job_mean_power_consumption\",\"job_min_power_consumption\",\"job_max_power_consumption\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e93e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group_id</th>\n",
       "      <th>time_limit_scaled</th>\n",
       "      <th>num_nodes_req</th>\n",
       "      <th>has_req_nodes</th>\n",
       "      <th>num_cores_req</th>\n",
       "      <th>cores_per_task</th>\n",
       "      <th>num_tasks_final</th>\n",
       "      <th>num_gpus_req</th>\n",
       "      <th>mem_req</th>\n",
       "      <th>has_req_threads_per_core</th>\n",
       "      <th>is_shared_job</th>\n",
       "      <th>num_tasks_missing_or_inconsistent</th>\n",
       "      <th>partition_final</th>\n",
       "      <th>dow_0</th>\n",
       "      <th>dow_1</th>\n",
       "      <th>dow_2</th>\n",
       "      <th>dow_3</th>\n",
       "      <th>dow_4</th>\n",
       "      <th>dow_5</th>\n",
       "      <th>dow_6</th>\n",
       "      <th>dom_1</th>\n",
       "      <th>dom_2</th>\n",
       "      <th>dom_3</th>\n",
       "      <th>dom_4</th>\n",
       "      <th>dom_5</th>\n",
       "      <th>dom_6</th>\n",
       "      <th>dom_7</th>\n",
       "      <th>dom_8</th>\n",
       "      <th>dom_9</th>\n",
       "      <th>dom_10</th>\n",
       "      <th>dom_11</th>\n",
       "      <th>dom_12</th>\n",
       "      <th>dom_13</th>\n",
       "      <th>dom_14</th>\n",
       "      <th>dom_15</th>\n",
       "      <th>dom_16</th>\n",
       "      <th>dom_17</th>\n",
       "      <th>dom_18</th>\n",
       "      <th>dom_19</th>\n",
       "      <th>dom_20</th>\n",
       "      <th>dom_21</th>\n",
       "      <th>dom_22</th>\n",
       "      <th>dom_23</th>\n",
       "      <th>dom_24</th>\n",
       "      <th>dom_25</th>\n",
       "      <th>dom_26</th>\n",
       "      <th>dom_27</th>\n",
       "      <th>dom_28</th>\n",
       "      <th>dom_29</th>\n",
       "      <th>dom_30</th>\n",
       "      <th>dom_31</th>\n",
       "      <th>hour_0</th>\n",
       "      <th>hour_1</th>\n",
       "      <th>hour_2</th>\n",
       "      <th>hour_3</th>\n",
       "      <th>hour_4</th>\n",
       "      <th>hour_5</th>\n",
       "      <th>hour_6</th>\n",
       "      <th>hour_7</th>\n",
       "      <th>hour_8</th>\n",
       "      <th>hour_9</th>\n",
       "      <th>hour_10</th>\n",
       "      <th>hour_11</th>\n",
       "      <th>hour_12</th>\n",
       "      <th>hour_13</th>\n",
       "      <th>hour_14</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "      <th>job_mean_power_consumption</th>\n",
       "      <th>job_min_power_consumption</th>\n",
       "      <th>job_max_power_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25200</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>519.930556</td>\n",
       "      <td>465.00</td>\n",
       "      <td>531.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25200</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>510.301724</td>\n",
       "      <td>363.75</td>\n",
       "      <td>533.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25200</td>\n",
       "      <td>-0.007838</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>512.069444</td>\n",
       "      <td>362.50</td>\n",
       "      <td>531.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25200</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>630.377358</td>\n",
       "      <td>520.00</td>\n",
       "      <td>860.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25200</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>860.208333</td>\n",
       "      <td>860.00</td>\n",
       "      <td>870.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231233</th>\n",
       "      <td>25200</td>\n",
       "      <td>0.944404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>920.000000</td>\n",
       "      <td>920.00</td>\n",
       "      <td>920.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231234</th>\n",
       "      <td>25200</td>\n",
       "      <td>-1.243395</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>863.000000</td>\n",
       "      <td>860.00</td>\n",
       "      <td>870.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231235</th>\n",
       "      <td>25200</td>\n",
       "      <td>0.386115</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>877.745455</td>\n",
       "      <td>610.00</td>\n",
       "      <td>1000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231236</th>\n",
       "      <td>25200</td>\n",
       "      <td>0.944404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>860.000000</td>\n",
       "      <td>860.00</td>\n",
       "      <td>860.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231237</th>\n",
       "      <td>25200</td>\n",
       "      <td>0.944404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>900.00</td>\n",
       "      <td>900.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231238 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        group_id  time_limit_scaled  num_nodes_req  has_req_nodes  \\\n",
       "0          25200          -0.007838             16              0   \n",
       "1          25200          -0.007838             16              0   \n",
       "2          25200          -0.007838             16              0   \n",
       "3          25200          -1.243395              1              0   \n",
       "4          25200          -1.243395              1              0   \n",
       "...          ...                ...            ...            ...   \n",
       "231233     25200           0.944404              1              0   \n",
       "231234     25200          -1.243395              1              1   \n",
       "231235     25200           0.386115              1              0   \n",
       "231236     25200           0.944404              1              0   \n",
       "231237     25200           0.944404              1              0   \n",
       "\n",
       "        num_cores_req  cores_per_task  num_tasks_final  num_gpus_req  mem_req  \\\n",
       "0                 256               4               64            64      475   \n",
       "1                 256               4               64            64      475   \n",
       "2                 256               4               64            64      475   \n",
       "3                  32              32                0             4       59   \n",
       "4                  32              32                0             4       59   \n",
       "...               ...             ...              ...           ...      ...   \n",
       "231233            128              32                4             4      237   \n",
       "231234              4               1                4             4        7   \n",
       "231235            128              16                8             4      234   \n",
       "231236            128              32                4             4      237   \n",
       "231237            128              32                4             4      237   \n",
       "\n",
       "        has_req_threads_per_core  is_shared_job  \\\n",
       "0                              0              0   \n",
       "1                              0              0   \n",
       "2                              0              0   \n",
       "3                              0              1   \n",
       "4                              0              1   \n",
       "...                          ...            ...   \n",
       "231233                         0              1   \n",
       "231234                         0              0   \n",
       "231235                         0              1   \n",
       "231236                         0              1   \n",
       "231237                         0              1   \n",
       "\n",
       "        num_tasks_missing_or_inconsistent  partition_final  dow_0  dow_1  \\\n",
       "0                                       0                1      0      0   \n",
       "1                                       0                1      0      0   \n",
       "2                                       0                1      0      0   \n",
       "3                                       1                1      0      0   \n",
       "4                                       1                1      0      0   \n",
       "...                                   ...              ...    ...    ...   \n",
       "231233                                  0                1      0      0   \n",
       "231234                                  0                1      0      0   \n",
       "231235                                  0                1      0      0   \n",
       "231236                                  0                1      0      0   \n",
       "231237                                  0                1      0      0   \n",
       "\n",
       "        dow_2  dow_3  dow_4  dow_5  dow_6  dom_1  dom_2  dom_3  dom_4  dom_5  \\\n",
       "0           0      0      0      0      1      0      0      0      0      0   \n",
       "1           0      0      0      0      1      0      0      0      0      0   \n",
       "2           0      0      0      0      1      0      0      0      0      0   \n",
       "3           0      0      0      0      1      0      0      0      0      0   \n",
       "4           0      0      0      0      1      0      0      0      0      0   \n",
       "...       ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "231233      1      0      0      0      0      0      0      0      0      0   \n",
       "231234      1      0      0      0      0      0      0      0      0      0   \n",
       "231235      1      0      0      0      0      0      0      0      0      0   \n",
       "231236      1      0      0      0      0      0      0      0      0      0   \n",
       "231237      1      0      0      0      0      0      0      0      0      0   \n",
       "\n",
       "        dom_6  dom_7  dom_8  dom_9  dom_10  dom_11  dom_12  dom_13  dom_14  \\\n",
       "0           0      0      0      0       0       0       0       0       0   \n",
       "1           0      0      0      0       0       0       0       0       0   \n",
       "2           0      0      0      0       0       0       0       0       0   \n",
       "3           0      0      0      0       0       0       0       0       0   \n",
       "4           0      0      0      0       0       0       0       0       0   \n",
       "...       ...    ...    ...    ...     ...     ...     ...     ...     ...   \n",
       "231233      0      1      0      0       0       0       0       0       0   \n",
       "231234      0      1      0      0       0       0       0       0       0   \n",
       "231235      0      1      0      0       0       0       0       0       0   \n",
       "231236      0      1      0      0       0       0       0       0       0   \n",
       "231237      0      1      0      0       0       0       0       0       0   \n",
       "\n",
       "        dom_15  dom_16  dom_17  dom_18  dom_19  dom_20  dom_21  dom_22  \\\n",
       "0            0       0       0       0       0       0       0       0   \n",
       "1            0       0       0       0       0       0       0       0   \n",
       "2            0       0       0       0       0       0       0       0   \n",
       "3            0       0       0       0       0       0       0       0   \n",
       "4            0       0       0       0       0       0       0       0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "231233       0       0       0       0       0       0       0       0   \n",
       "231234       0       0       0       0       0       0       0       0   \n",
       "231235       0       0       0       0       0       0       0       0   \n",
       "231236       0       0       0       0       0       0       0       0   \n",
       "231237       0       0       0       0       0       0       0       0   \n",
       "\n",
       "        dom_23  dom_24  dom_25  dom_26  dom_27  dom_28  dom_29  dom_30  \\\n",
       "0            0       0       0       0       0       0       0       0   \n",
       "1            0       0       0       0       0       0       0       0   \n",
       "2            0       0       0       0       0       0       0       0   \n",
       "3            0       0       0       0       0       0       0       0   \n",
       "4            0       0       0       0       0       0       0       0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "231233       0       0       0       0       0       0       0       0   \n",
       "231234       0       0       0       0       0       0       0       0   \n",
       "231235       0       0       0       0       0       0       0       0   \n",
       "231236       0       0       0       0       0       0       0       0   \n",
       "231237       0       0       0       0       0       0       0       0   \n",
       "\n",
       "        dom_31  hour_0  hour_1  hour_2  hour_3  hour_4  hour_5  hour_6  \\\n",
       "0            1       0       0       0       0       0       0       0   \n",
       "1            1       0       0       0       0       0       0       0   \n",
       "2            1       0       0       0       0       0       0       0   \n",
       "3            1       0       0       0       0       0       0       0   \n",
       "4            1       0       0       0       0       0       0       0   \n",
       "...        ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "231233       0       0       0       0       0       0       1       0   \n",
       "231234       0       0       0       0       0       0       0       0   \n",
       "231235       0       0       0       0       0       0       0       0   \n",
       "231236       0       0       0       0       0       0       0       1   \n",
       "231237       0       0       1       0       0       0       0       0   \n",
       "\n",
       "        hour_7  hour_8  hour_9  hour_10  hour_11  hour_12  hour_13  hour_14  \\\n",
       "0            0       0       0        0        0        0        0        0   \n",
       "1            0       0       0        0        0        0        0        0   \n",
       "2            0       0       0        0        0        0        0        0   \n",
       "3            0       0       0        0        0        0        0        0   \n",
       "4            0       0       0        0        0        0        0        0   \n",
       "...        ...     ...     ...      ...      ...      ...      ...      ...   \n",
       "231233       0       0       0        0        0        0        0        0   \n",
       "231234       1       0       0        0        0        0        0        0   \n",
       "231235       0       0       1        0        0        0        0        0   \n",
       "231236       0       0       0        0        0        0        0        0   \n",
       "231237       0       0       0        0        0        0        0        0   \n",
       "\n",
       "        hour_15  hour_16  hour_17  hour_18  hour_19  hour_20  hour_21  \\\n",
       "0             0        0        0        0        0        0        0   \n",
       "1             0        0        0        0        0        0        0   \n",
       "2             0        0        0        0        0        0        0   \n",
       "3             0        0        0        0        0        0        0   \n",
       "4             0        0        0        0        0        0        0   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "231233        0        0        0        0        0        0        0   \n",
       "231234        0        0        0        0        0        0        0   \n",
       "231235        0        0        0        0        0        0        0   \n",
       "231236        0        0        0        0        0        0        0   \n",
       "231237        0        0        0        0        0        0        0   \n",
       "\n",
       "        hour_22  hour_23  job_mean_power_consumption  \\\n",
       "0             1        0                  519.930556   \n",
       "1             1        0                  510.301724   \n",
       "2             1        0                  512.069444   \n",
       "3             0        1                  630.377358   \n",
       "4             0        1                  860.208333   \n",
       "...         ...      ...                         ...   \n",
       "231233        0        0                  920.000000   \n",
       "231234        0        0                  863.000000   \n",
       "231235        0        0                  877.745455   \n",
       "231236        0        0                  860.000000   \n",
       "231237        0        0                  900.000000   \n",
       "\n",
       "        job_min_power_consumption  job_max_power_consumption  \n",
       "0                          465.00                    531.250  \n",
       "1                          363.75                    533.125  \n",
       "2                          362.50                    531.875  \n",
       "3                          520.00                    860.000  \n",
       "4                          860.00                    870.000  \n",
       "...                           ...                        ...  \n",
       "231233                     920.00                    920.000  \n",
       "231234                     860.00                    870.000  \n",
       "231235                     610.00                   1000.000  \n",
       "231236                     860.00                    860.000  \n",
       "231237                     900.00                    900.000  \n",
       "\n",
       "[231238 rows x 78 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.astype({col: int for col in df.select_dtypes(include='bool').columns})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1ed6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_columns = [\"job_mean_power_consumption\", \"job_min_power_consumption\", \"job_max_power_consumption\"]\n",
    "X_columns = [col for col in df.columns if col not in Y_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d629750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c082e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE THE SPLITS\n",
    "\n",
    "X,y = df[X_columns], df[Y_columns]\n",
    "\n",
    "### FOR CLASSIC MODELS\n",
    "\n",
    "# Assuming you have your data in X (features) and y (labels)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit only on train!\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\n",
    "### FOR TORCH MODELS\n",
    "\n",
    "# Convert to tensors (on CPU)\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)  # Use float32 for regression\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 1028\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ad2dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataset, r\"C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\train_dataset.pt\")\n",
    "torch.save(val_dataset, r\"C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\val_dataset.pt\")\n",
    "torch.save(test_dataset, r\"C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\test_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62a772fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches - Train: 158, Val: 34, Test: 34\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of batches - Train: {len(train_loader)}, Val: {len(val_loader)}, Test: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73d04a81",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (torch_models.py, line 124)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[36m(most recent call last)\u001b[39m:\n",
      "  File \u001b[92m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:3699\u001b[39m in \u001b[95mrun_code\u001b[39m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[36m  \u001b[39m\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mimport torch_models\u001b[39m\n",
      "  \u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\models/code_models\\torch_models.py:124\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m<<<<<<< Updated upstream\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./models/code_models/')\n",
    "\n",
    "import sklearn_models\n",
    "import torch_models\n",
    "import training_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b006a97",
   "metadata": {},
   "source": [
    "# SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78398ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_model = sklearn_models.get_random_forest()\n",
    "\n",
    "# rf_trainer = training_utils.SklearnTrainer(\n",
    "#     model=rf_model,\n",
    "#     model_name=\"RandomForest_Default\",\n",
    "#     project_name=\"Test\",\n",
    "#     entity=\"iqbalch-universidad-carlos-iii-de-madrid\" \n",
    "# )\n",
    "\n",
    "# rf_model, rf_metrics = rf_trainer.train(\n",
    "#     X_train_scaled, y_train,\n",
    "#     X_val_scaled, y_val,\n",
    "#     config= rf_model.get_params()\n",
    "# )\n",
    "\n",
    "# print(\"\\nValidation Metrics:\")\n",
    "# for key, value in rf_metrics.items():\n",
    "#     if 'val' in key:\n",
    "#         print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# test_metrics, test_predictions = training_utils.evaluate_model(\n",
    "#     rf_model, X_test_scaled, y_test, model_type=\"sklearn\"\n",
    "# )\n",
    "\n",
    "# print(\"\\nTest Set Metrics:\")\n",
    "# for key, value in test_metrics.items():\n",
    "#     print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d78abd",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc83d77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dae09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = {\n",
    "    'hidden_dims': [512, 256, 128, 64, 32],      # Your best architecture\n",
    "    'dropout': 0.45804528506994224,      # Your best dropout\n",
    "    'lr': 0.0021210520500481852,         # Learning rate\n",
    "    'weight_decay': 0.000001,             # Weight decay\n",
    "    'batch_size': 2048,                  # Batch size\n",
    "    'epochs': 150,                       # Training epochs\n",
    "    'patience': 80                       # Early stopping patience\n",
    "}\n",
    "config_name = \"DenseNN_Sweep_Test5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e91b25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">DenseNN_Sweep_Test5</strong> at: <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/sdszzo32' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/sdszzo32</a><br> View project at: <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251218_193515-sdszzo32\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\wandb\\run-20251218_193535-tqzmuo5n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/tqzmuo5n' target=\"_blank\">DenseNN_Sweep_Test5</a></strong> to <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/tqzmuo5n' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/tqzmuo5n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING AND TEST EVALUATION\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"Test\",\n",
    "    entity=\"100451397-universidad-carlos-iii-de-madrid\",\n",
    "    name=config_name,\n",
    "    config=best_config,\n",
    "    tags=[\"train_and_test\", config_name]\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING AND TEST EVALUATION\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Create data loaders with best batch size\n",
    "train_loader_best = DataLoader(train_dataset, batch_size=best_config['batch_size'], shuffle=True)\n",
    "val_loader_best = DataLoader(val_dataset, batch_size=best_config['batch_size'], shuffle=False)\n",
    "test_loader_best = DataLoader(test_dataset, batch_size=best_config['batch_size'], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11161869",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "operator torchvision::nms does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m importlib.reload(torch_models)\n\u001b[32m     13\u001b[39m importlib.reload(training_utils)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchlens\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtl\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Create model with best architecture\u001b[39;00m\n\u001b[32m     17\u001b[39m test_model = torch_models.DenseNN(\n\u001b[32m     18\u001b[39m     input_dim=X_train_scaled.shape[\u001b[32m1\u001b[39m],\n\u001b[32m     19\u001b[39m     hidden_dims=best_config[\u001b[33m'\u001b[39m\u001b[33mhidden_dims\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     20\u001b[39m     output_dim=\u001b[32m3\u001b[39m,\n\u001b[32m     21\u001b[39m     dropout=best_config[\u001b[33m'\u001b[39m\u001b[33mdropout\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     22\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\torchlens\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\" Top level package: make the user-facing functions top-level, rest accessed as submodules.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01muser_funcs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m log_forward_pass, show_model_graph, get_model_metadata, validate_saved_activations, \\\n\u001b[32m      4\u001b[39m     validate_batch_of_models_and_inputs\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_history\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelHistory\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor_log\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorLogEntry, RolledTensorLogEntry\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\torchlens\\user_funcs.py:12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhelper_funcs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (get_vars_of_type_from_obj, set_random_seed, warn_parallel)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_history\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     13\u001b[39m     ModelHistory,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_model_and_save_specified_activations\u001b[39m(\n\u001b[32m     18\u001b[39m         model: nn.Module,\n\u001b[32m     19\u001b[39m         input_args: Union[torch.Tensor, List[Any]],\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m         random_seed: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     30\u001b[39m ) -> ModelHistory:\n\u001b[32m     31\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Internal function that runs the given input through the given model, and saves the\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[33;03m    specified activations, as given by the tensor numbers (these will not be visible to the user;\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03m    they will be generated from the nicer human-readable names and then fed in).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m \u001b[33;03m        ModelHistory object with full log of the forward pass\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\torchlens\\model_history.py:6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OrderedDict, defaultdict\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, Dict, List, Optional, Set, Tuple\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcleanup\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _remove_log_entry, cleanup\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdecorate_torch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorate_pytorch\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhelper_funcs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     human_readable_size,\n\u001b[32m     10\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\torchlens\\cleanup.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MODEL_HISTORY_FIELD_ORDER\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhelper_funcs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m remove_entry_from_list\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor_log\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TensorLogEntry\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\torchlens\\constants.py:438\u001b[39m\n\u001b[32m    435\u001b[39m ORIG_TORCH_FUNCS = OVERRIDABLE_FUNCS + IGNORED_FUNCS\n\u001b[32m    437\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\n\u001b[32m    440\u001b[39m     ORIG_TORCH_FUNCS += TORCHVISION_FUNCS\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\torchvision\\__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mextension\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\torchvision\\_meta_registrations.py:163\u001b[39m\n\u001b[32m    153\u001b[39m     torch._check(\n\u001b[32m    154\u001b[39m         grad.dtype == rois.dtype,\n\u001b[32m    155\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m: (\n\u001b[32m   (...)\u001b[39m\u001b[32m    158\u001b[39m         ),\n\u001b[32m    159\u001b[39m     )\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m grad.new_empty((batch_size, channels, height, width))\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m \u001b[38;5;129;43m@torch\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlibrary\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister_fake\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtorchvision::nms\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43mmeta_nms\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou_threshold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mboxes should be a 2d tensor, got \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43mD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdets\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mboxes should have 4 elements in dimension 1, got \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdets\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\torch\\library.py:1069\u001b[39m, in \u001b[36mregister_fake.<locals>.register\u001b[39m\u001b[34m(func)\u001b[39m\n\u001b[32m   1067\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1068\u001b[39m     use_lib = lib\n\u001b[32m-> \u001b[39m\u001b[32m1069\u001b[39m \u001b[43muse_lib\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_register_fake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacklevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstacklevel\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_override\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_override\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\torch\\library.py:219\u001b[39m, in \u001b[36mLibrary._register_fake\u001b[39m\u001b[34m(self, op_name, fn, _stacklevel, allow_override)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    217\u001b[39m     func_to_register = fn\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m handle = \u001b[43mentry\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfake_impl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc_to_register\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_override\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_override\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[38;5;28mself\u001b[39m._registration_handles.append(handle)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\torch\\_library\\fake_impl.py:50\u001b[39m, in \u001b[36mFakeImplHolder.register\u001b[39m\u001b[34m(self, func, source, lib, allow_override)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.kernel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     46\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.qualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33malready has an fake impl registered at \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     48\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.kernel.source\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     49\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_dispatch_has_kernel_for_dispatch_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mqualname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMeta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     52\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mregister_fake(...): the operator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.qualname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     53\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33malready has an DispatchKey::Meta implementation via a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mregister_fake.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     57\u001b[39m     )\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch._C._dispatch_has_kernel_for_dispatch_key(\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.qualname, \u001b[33m\"\u001b[39m\u001b[33mCompositeImplicitAutograd\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     61\u001b[39m ):\n",
      "\u001b[31mRuntimeError\u001b[39m: operator torchvision::nms does not exist"
     ]
    }
   ],
   "source": [
    "# Import/reload modules to ensure latest version\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "if './models/code_models/' not in sys.path:\n",
    "    sys.path.append('./models/code_models/')\n",
    "\n",
    "import sklearn_models\n",
    "import torch_models\n",
    "import training_utils\n",
    "\n",
    "importlib.reload(torch_models)\n",
    "importlib.reload(training_utils)\n",
    "\n",
    "# Create model with best architecture\n",
    "test_model = torch_models.DenseNN(\n",
    "    input_dim=X_train_scaled.shape[1],\n",
    "    hidden_dims=best_config['hidden_dims'],\n",
    "    output_dim=3,\n",
    "    dropout=best_config['dropout']\n",
    ")\n",
    "\n",
    "n_params = sum(p.numel() for p in test_model.parameters())\n",
    "print(f\"Model created: {n_params:,} parameters\")\n",
    "print(f\"Architecture: {best_config['hidden_dims']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07edacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\triton\\knobs.py:212: UserWarning: Failed to find cuobjdump.exe\n",
      "  warnings.warn(f\"Failed to find {binary}\")\n",
      "c:\\Users\\Jaime\\miniconda3\\Lib\\site-packages\\triton\\knobs.py:212: UserWarning: Failed to find nvdisasm.exe\n",
      "  warnings.warn(f\"Failed to find {binary}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150 - Train Loss: 298046.2414, Val Loss: 260632.6912, Val RMSE: 510.5220\n",
      "Epoch 20/150 - Train Loss: 74614.1290, Val Loss: 56134.5044, Val RMSE: 236.9272\n",
      "Epoch 30/150 - Train Loss: 59269.3880, Val Loss: 43461.2401, Val RMSE: 208.4736\n",
      "Epoch 40/150 - Train Loss: 58109.3625, Val Loss: 42420.8672, Val RMSE: 205.9633\n",
      "Epoch 50/150 - Train Loss: 57168.7047, Val Loss: 41738.4577, Val RMSE: 204.2999\n",
      "Epoch 60/150 - Train Loss: 56652.8437, Val Loss: 40889.9467, Val RMSE: 202.2126\n",
      "Epoch 70/150 - Train Loss: 56029.3220, Val Loss: 41261.4154, Val RMSE: 203.1291\n",
      "Epoch 80/150 - Train Loss: 55798.4491, Val Loss: 40697.8228, Val RMSE: 201.7370\n",
      "Epoch 90/150 - Train Loss: 55749.7694, Val Loss: 40332.9968, Val RMSE: 200.8308\n",
      "Epoch 100/150 - Train Loss: 55517.5563, Val Loss: 40053.1137, Val RMSE: 200.1327\n",
      "Epoch 110/150 - Train Loss: 55700.8180, Val Loss: 40225.0264, Val RMSE: 200.5618\n",
      "Epoch 120/150 - Train Loss: 55198.4420, Val Loss: 40553.3458, Val RMSE: 201.3786\n",
      "Epoch 130/150 - Train Loss: 54961.3838, Val Loss: 39959.2358, Val RMSE: 199.8981\n",
      "Epoch 140/150 - Train Loss: 55595.1857, Val Loss: 39952.7891, Val RMSE: 199.8819\n",
      "Epoch 150/150 - Train Loss: 55368.2702, Val Loss: 40323.5108, Val RMSE: 200.8071\n",
      "\n",
      "Best Validation Metrics:\n",
      "  val_loss: 40323.5108\n",
      "  val_rmse: 200.8071\n",
      "  val_rmse_mean_power: 171.4848\n",
      "  val_mae_mean_power: 127.6181\n",
      "  val_r2_mean_power: 0.2054\n",
      "  val_rmse_min_power: 183.2238\n",
      "  val_mae_min_power: 130.6594\n",
      "  val_r2_min_power: 0.0992\n",
      "  val_rmse_max_power: 240.8028\n",
      "  val_mae_max_power: 180.7437\n",
      "  val_r2_max_power: 0.1884\n",
      "  best_val_loss: 39663.7459\n"
     ]
    }
   ],
   "source": [
    "# Create trainer\n",
    "trainer = training_utils.PyTorchTrainer(\n",
    "    model=test_model,\n",
    "    model_name=f\"DenseNN_{config_name}\",\n",
    "    project_name=None,  # Already initialized\n",
    "    entity=None\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "trained_model, metrics = trainer.train(\n",
    "    train_loader=train_loader_best,\n",
    "    val_loader=val_loader_best,\n",
    "    epochs=best_config['epochs'],\n",
    "    lr=best_config['lr'],\n",
    "    weight_decay=best_config['weight_decay'],\n",
    "    patience=best_config['patience']\n",
    ")\n",
    "\n",
    "print(\"\\nBest Validation Metrics:\")\n",
    "for key, value in metrics.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7cc185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPUTING TEST METRICS\n",
      "================================================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "TEST SET EVALUATION\n",
      "==================================================\n",
      "\n",
      "Overall Metrics:\n",
      "  RMSE: 204.1596\n",
      "  MAE:  148.4495\n",
      "  R²:   0.1624\n",
      "\n",
      "Per-Output Metrics:\n",
      "\n",
      "  node:\n",
      "    RMSE: 174.4006\n",
      "    MAE:  129.4845\n",
      "    R²:   0.2033\n",
      "\n",
      "  mem:\n",
      "    RMSE: 187.1715\n",
      "    MAE:  133.1850\n",
      "    R²:   0.0972\n",
      "\n",
      "  cpu:\n",
      "    RMSE: 244.1220\n",
      "    MAE:  182.6783\n",
      "    R²:   0.1868\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPUTING TEST METRICS\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "test_metrics, test_predictions = trainer.evaluate_test_set(test_loader_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8f34ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TEST SET RESULTS\n",
      "================================================================================\n",
      "\n",
      "Overall Test Metrics:\n",
      "  MSE:  41681.1367\n",
      "  RMSE: 204.1596\n",
      "  MAE:  148.4495\n",
      "  R²:   0.1624\n",
      "\n",
      "================================================================================\n",
      "PER-OUTPUT POWER CONSUMPTION METRICS\n",
      "================================================================================\n",
      "\n",
      "job_mean_power_consumption:\n",
      "  MSE:  30415.5586\n",
      "  RMSE: 174.4006\n",
      "  MAE:  129.4845\n",
      "  R²:   0.2033\n",
      "\n",
      "job_min_power_consumption:\n",
      "  MSE:  35033.1602\n",
      "  RMSE: 187.1715\n",
      "  MAE:  133.1850\n",
      "  R²:   0.0972\n",
      "\n",
      "job_max_power_consumption:\n",
      "  MSE:  59595.5586\n",
      "  RMSE: 244.1220\n",
      "  MAE:  182.6783\n",
      "  R²:   0.1868\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nOverall Test Metrics:\")\n",
    "print(f\"  MSE:  {test_metrics['mse']:.4f}\")\n",
    "print(f\"  RMSE: {test_metrics['rmse']:.4f}\")\n",
    "print(f\"  MAE:  {test_metrics['mae']:.4f}\")\n",
    "print(f\"  R²:   {test_metrics['r2']:.4f}\")\n",
    "\n",
    "# Display per-output metrics for power consumption\n",
    "if 'mse_per_output' in test_metrics:\n",
    "    output_names = ['job_mean_power_consumption', 'job_min_power_consumption', 'job_max_power_consumption']\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"PER-OUTPUT POWER CONSUMPTION METRICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, name in enumerate(output_names):\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  MSE:  {test_metrics['mse_per_output'][i]:.4f}\")\n",
    "        print(f\"  RMSE: {test_metrics['rmse_per_output'][i]:.4f}\")\n",
    "        print(f\"  MAE:  {test_metrics['mae_per_output'][i]:.4f}\")\n",
    "        print(f\"  R²:   {test_metrics['r2_per_output'][i]:.4f}\")\n",
    "    \n",
    "    # Log per-output metrics to wandb\n",
    "    wandb.log({\n",
    "        'test/mean_power_mse': test_metrics['mse_per_output'][0],\n",
    "        'test/mean_power_rmse': test_metrics['rmse_per_output'][0],\n",
    "        'test/mean_power_mae': test_metrics['mae_per_output'][0],\n",
    "        'test/mean_power_r2': test_metrics['r2_per_output'][0],\n",
    "        'test/min_power_mse': test_metrics['mse_per_output'][1],\n",
    "        'test/min_power_rmse': test_metrics['rmse_per_output'][1],\n",
    "        'test/min_power_mae': test_metrics['mae_per_output'][1],\n",
    "        'test/min_power_r2': test_metrics['r2_per_output'][1],\n",
    "        'test/max_power_mse': test_metrics['mse_per_output'][2],\n",
    "        'test/max_power_rmse': test_metrics['rmse_per_output'][2],\n",
    "        'test/max_power_mae': test_metrics['mae_per_output'][2],\n",
    "        'test/max_power_r2': test_metrics['r2_per_output'][2],\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1413ed51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Model saved to: C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\models\\best_model_5.pt\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>lr</td><td>█████████████▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>mae</td><td>▁</td></tr><tr><td>mse</td><td>▁</td></tr><tr><td>r2</td><td>▁</td></tr><tr><td>rmse</td><td>▁</td></tr><tr><td>test/cpu_mae</td><td>▁</td></tr><tr><td>test/cpu_mse</td><td>▁</td></tr><tr><td>test/cpu_r2</td><td>▁</td></tr><tr><td>test/cpu_rmse</td><td>▁</td></tr><tr><td>+36</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>149</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>mae</td><td>148.44954</td></tr><tr><td>mse</td><td>41681.13672</td></tr><tr><td>r2</td><td>0.16241</td></tr><tr><td>rmse</td><td>204.15959</td></tr><tr><td>test/cpu_mae</td><td>182.67825</td></tr><tr><td>test/cpu_mse</td><td>59595.55859</td></tr><tr><td>test/cpu_r2</td><td>0.18681</td></tr><tr><td>test/cpu_rmse</td><td>244.12202</td></tr><tr><td>+36</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">DenseNN_Sweep_Test5</strong> at: <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/tqzmuo5n' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test/runs/tqzmuo5n</a><br> View project at: <a href='https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/100451397-universidad-carlos-iii-de-madrid/Test</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251218_193535-tqzmuo5n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING AND TEST EVALUATION COMPLETE\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model_save_path = r'C:\\Users\\Jaime\\Documents\\GitHub\\DS-HPE\\models\\best_model_5.pt'\n",
    "torch.save(trained_model.state_dict(), model_save_path)\n",
    "print(f\"\\n✓ Model saved to: {model_save_path}\")\n",
    "\n",
    "# Finish W&B run\n",
    "wandb.finish()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING AND TEST EVALUATION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
