{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2228800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "# import ast\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "# import torch\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import xgboost as xgb\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be20d1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessing module\n",
    "from preprocessing_pipeline import pipeline_features\n",
    "# Import W&B module for Sklearn\n",
    "# from models.training_utils import SklearnTrainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f26da3",
   "metadata": {},
   "source": [
    "#### Try W&B config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ec8771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\adeli\\Documents 4-Q1\\Data Project\\GitHub HPE Code\\DS-HPE\\wandb\\run-20251128_214844-3pgi6lf4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/100496657-universidad-carlos-iii-de-madrid/Node_Power_Consumption/runs/3pgi6lf4' target=\"_blank\">test-run</a></strong> to <a href='https://wandb.ai/100496657-universidad-carlos-iii-de-madrid/Node_Power_Consumption' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/100496657-universidad-carlos-iii-de-madrid/Node_Power_Consumption' target=\"_blank\">https://wandb.ai/100496657-universidad-carlos-iii-de-madrid/Node_Power_Consumption</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/100496657-universidad-carlos-iii-de-madrid/Node_Power_Consumption/runs/3pgi6lf4' target=\"_blank\">https://wandb.ai/100496657-universidad-carlos-iii-de-madrid/Node_Power_Consumption/runs/3pgi6lf4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>metric</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>metric</td><td>1</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test-run</strong> at: <a href='https://wandb.ai/100496657-universidad-carlos-iii-de-madrid/Node_Power_Consumption/runs/3pgi6lf4' target=\"_blank\">https://wandb.ai/100496657-universidad-carlos-iii-de-madrid/Node_Power_Consumption/runs/3pgi6lf4</a><br> View project at: <a href='https://wandb.ai/100496657-universidad-carlos-iii-de-madrid/Node_Power_Consumption' target=\"_blank\">https://wandb.ai/100496657-universidad-carlos-iii-de-madrid/Node_Power_Consumption</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251128_214844-3pgi6lf4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import wandb and run a test to see ig it works\n",
    "wandb_project = \"Node_Power_Consumption\"\n",
    "wandb.init(project=wandb_project, name=\"test-run\")\n",
    "wandb.log({\"metric\": 1})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca6ff3",
   "metadata": {},
   "source": [
    "### Prepare the dataset for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "91a643bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Marconi 100 data (job table)\n",
    "df_raw = pd.read_parquet(\"job_table.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48c8b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30335a6",
   "metadata": {},
   "source": [
    "##### Dataset with node_consumption as target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c216c78d",
   "metadata": {},
   "source": [
    "We choose linear= False as we are trying a XGBoost regression.<br>\n",
    "Use include_cpu=include_mem= False, we leave as target only node consumption stats: min, mean, max.<br>\n",
    "Use two groups: main, other.<br>\n",
    "Leave num_tasks_option= 1 : imputes NAs, leaves the incorrect values of num_tasks as such. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f6db82ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option leave two groups: main, other.\n",
      "Option Impute NAs, leave incorrect num_tasks entries.\n",
      "Option generate DS for tree models.\n"
     ]
    }
   ],
   "source": [
    "df= pipeline_features(df_raw, linear=False, include_cpu=False, include_mem=False, group_option=2, num_tasks_option=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ff6621c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['group', 'num_tasks_final', 'num_tasks_missing_or_inconsistent',\n",
       "       'submit_time', 'time_limit', 'time_limit_cat', 'num_nodes_req',\n",
       "       'has_req_nodes', 'num_cores_req', 'cores_per_task', 'num_gpus_req',\n",
       "       'mem_req', 'has_req_threads_per_core', 'is_shared_job', 'dow_0',\n",
       "       'dow_1', 'dow_2', 'dow_3', 'dow_4', 'dow_5', 'dow_6', 'dom_1', 'dom_2',\n",
       "       'dom_3', 'dom_4', 'dom_5', 'dom_6', 'dom_7', 'dom_8', 'dom_9', 'dom_10',\n",
       "       'dom_11', 'dom_12', 'dom_13', 'dom_14', 'dom_15', 'dom_16', 'dom_17',\n",
       "       'dom_18', 'dom_19', 'dom_20', 'dom_21', 'dom_22', 'dom_23', 'dom_24',\n",
       "       'dom_25', 'dom_26', 'dom_27', 'dom_28', 'dom_29', 'dom_30', 'dom_31',\n",
       "       'hour_0', 'hour_1', 'hour_2', 'hour_3', 'hour_4', 'hour_5', 'hour_6',\n",
       "       'hour_7', 'hour_8', 'hour_9', 'hour_10', 'hour_11', 'hour_12',\n",
       "       'hour_13', 'hour_14', 'hour_15', 'hour_16', 'hour_17', 'hour_18',\n",
       "       'hour_19', 'hour_20', 'hour_21', 'hour_22', 'hour_23', 'node_power_min',\n",
       "       'node_power_mean', 'node_power_max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c2deae73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dow\"] = df[\"submit_time\"].dt.dayofweek \n",
    "df[\"dom\"] = df[\"submit_time\"].dt.day                  # 1–31\n",
    "df[\"hour\"] = df[\"submit_time\"].dt.hour\n",
    "df[\"is_weekend\"] = df[\"dow\"].isin([5,6]).astype(int)\n",
    "df[\"month\"] = df[\"submit_time\"].dt.month\n",
    "df[\"is_night\"] = ((df[\"hour\"] < 7) | (df[\"hour\"] >= 22)).astype(int)\n",
    "df[\"is_peak\"] = df[\"hour\"].between(9, 18).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9d4b7ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"submit_time\", ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "43bd99f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = (\n",
    "    df.filter(like='dow_').columns.tolist() +\n",
    "    df.filter(like='dom_').columns.tolist() +\n",
    "    df.filter(like='hour_').columns.tolist()\n",
    ")\n",
    "df = df.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b11c5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['group', 'num_tasks_final', 'num_tasks_missing_or_inconsistent',\n",
       "       'time_limit', 'time_limit_cat', 'num_nodes_req', 'has_req_nodes',\n",
       "       'num_cores_req', 'cores_per_task', 'num_gpus_req', 'mem_req',\n",
       "       'has_req_threads_per_core', 'is_shared_job', 'node_power_min',\n",
       "       'node_power_mean', 'node_power_max', 'dow', 'dom', 'hour', 'is_weekend',\n",
       "       'month', 'is_night', 'is_peak'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2a8e4af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns to category codes\n",
    "categorical_cols = [\"group\", \"time_limit_cat\"]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f8e93e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>num_tasks_final</th>\n",
       "      <th>num_tasks_missing_or_inconsistent</th>\n",
       "      <th>time_limit</th>\n",
       "      <th>time_limit_cat</th>\n",
       "      <th>num_nodes_req</th>\n",
       "      <th>has_req_nodes</th>\n",
       "      <th>num_cores_req</th>\n",
       "      <th>cores_per_task</th>\n",
       "      <th>num_gpus_req</th>\n",
       "      <th>mem_req</th>\n",
       "      <th>has_req_threads_per_core</th>\n",
       "      <th>is_shared_job</th>\n",
       "      <th>node_power_min</th>\n",
       "      <th>node_power_mean</th>\n",
       "      <th>node_power_max</th>\n",
       "      <th>dow</th>\n",
       "      <th>dom</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>month</th>\n",
       "      <th>is_night</th>\n",
       "      <th>is_peak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7440</td>\n",
       "      <td>8318.888889</td>\n",
       "      <td>8500</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5820</td>\n",
       "      <td>8164.827586</td>\n",
       "      <td>8530</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5800</td>\n",
       "      <td>8193.111111</td>\n",
       "      <td>8510</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>520</td>\n",
       "      <td>630.377358</td>\n",
       "      <td>860</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>860</td>\n",
       "      <td>860.208333</td>\n",
       "      <td>870</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group  num_tasks_final  num_tasks_missing_or_inconsistent  time_limit  \\\n",
       "0      0               64                              False         270   \n",
       "1      0               64                              False         270   \n",
       "2      0               64                              False         270   \n",
       "3      0                0                               True          30   \n",
       "4      0                0                               True          30   \n",
       "\n",
       "   time_limit_cat  num_nodes_req  has_req_nodes  num_cores_req  \\\n",
       "0               1             16              0            256   \n",
       "1               1             16              0            256   \n",
       "2               1             16              0            256   \n",
       "3               0              1              0             32   \n",
       "4               0              1              0             32   \n",
       "\n",
       "   cores_per_task  num_gpus_req  mem_req  has_req_threads_per_core  \\\n",
       "0               4            64      475                         0   \n",
       "1               4            64      475                         0   \n",
       "2               4            64      475                         0   \n",
       "3              32             4       59                         0   \n",
       "4              32             4       59                         0   \n",
       "\n",
       "   is_shared_job  node_power_min  node_power_mean  node_power_max  dow  dom  \\\n",
       "0              0            7440      8318.888889            8500    6   31   \n",
       "1              0            5820      8164.827586            8530    6   31   \n",
       "2              0            5800      8193.111111            8510    6   31   \n",
       "3              1             520       630.377358             860    6   31   \n",
       "4              1             860       860.208333             870    6   31   \n",
       "\n",
       "   hour  is_weekend  month  is_night  is_peak  \n",
       "0    22           1      5         1        0  \n",
       "1    22           1      5         1        0  \n",
       "2    22           1      5         1        0  \n",
       "3    23           1      5         1        0  \n",
       "4    23           1      5         1        0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb5ca117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target columns\n",
    "target_cols = [\n",
    "    \"node_power_min\",\n",
    "    \"node_power_mean\",\n",
    "    \"node_power_max\"\n",
    "]\n",
    "\n",
    "feature_cols = [\n",
    "    'group',\n",
    "    'num_tasks_final',\n",
    "    'num_tasks_missing_or_inconsistent',\n",
    "    'time_limit',\n",
    "    'time_limit_cat',\n",
    "    'num_nodes_req',\n",
    "    'has_req_nodes',\n",
    "    'num_cores_req',\n",
    "    'cores_per_task',\n",
    "    'num_gpus_req',\n",
    "    'mem_req',\n",
    "    'has_req_threads_per_core',\n",
    "    'is_shared_job',\n",
    "    'dow', 'dom', 'hour', 'is_weekend', 'month', 'is_night', 'is_peak'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb13627b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "# Check that the number of feature and target columns matches the total number of columns in the dataframe\n",
    "print(len(feature_cols)+len(target_cols))\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6e4dba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split df into X and Y\n",
    "X = df[feature_cols].copy()\n",
    "Y = df[target_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84fe095e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>num_tasks_final</th>\n",
       "      <th>num_tasks_missing_or_inconsistent</th>\n",
       "      <th>time_limit</th>\n",
       "      <th>time_limit_cat</th>\n",
       "      <th>num_nodes_req</th>\n",
       "      <th>has_req_nodes</th>\n",
       "      <th>num_cores_req</th>\n",
       "      <th>cores_per_task</th>\n",
       "      <th>num_gpus_req</th>\n",
       "      <th>mem_req</th>\n",
       "      <th>has_req_threads_per_core</th>\n",
       "      <th>is_shared_job</th>\n",
       "      <th>dow</th>\n",
       "      <th>dom</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>month</th>\n",
       "      <th>is_night</th>\n",
       "      <th>is_peak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>False</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>475</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   group  num_tasks_final  num_tasks_missing_or_inconsistent  time_limit  \\\n",
       "0      0               64                              False         270   \n",
       "1      0               64                              False         270   \n",
       "2      0               64                              False         270   \n",
       "3      0                0                               True          30   \n",
       "4      0                0                               True          30   \n",
       "\n",
       "   time_limit_cat  num_nodes_req  has_req_nodes  num_cores_req  \\\n",
       "0               1             16              0            256   \n",
       "1               1             16              0            256   \n",
       "2               1             16              0            256   \n",
       "3               0              1              0             32   \n",
       "4               0              1              0             32   \n",
       "\n",
       "   cores_per_task  num_gpus_req  mem_req  has_req_threads_per_core  \\\n",
       "0               4            64      475                         0   \n",
       "1               4            64      475                         0   \n",
       "2               4            64      475                         0   \n",
       "3              32             4       59                         0   \n",
       "4              32             4       59                         0   \n",
       "\n",
       "   is_shared_job  dow  dom  hour  is_weekend  month  is_night  is_peak  \n",
       "0              0    6   31    22           1      5         1        0  \n",
       "1              0    6   31    22           1      5         1        0  \n",
       "2              0    6   31    22           1      5         1        0  \n",
       "3              1    6   31    23           1      5         1        0  \n",
       "4              1    6   31    23           1      5         1        0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "257c3e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_power_min</th>\n",
       "      <th>node_power_mean</th>\n",
       "      <th>node_power_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7440</td>\n",
       "      <td>8318.888889</td>\n",
       "      <td>8500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5820</td>\n",
       "      <td>8164.827586</td>\n",
       "      <td>8530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5800</td>\n",
       "      <td>8193.111111</td>\n",
       "      <td>8510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>520</td>\n",
       "      <td>630.377358</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>860</td>\n",
       "      <td>860.208333</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_power_min  node_power_mean  node_power_max\n",
       "0            7440      8318.888889            8500\n",
       "1            5820      8164.827586            8530\n",
       "2            5800      8193.111111            8510\n",
       "3             520       630.377358             860\n",
       "4             860       860.208333             870"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a52d0737",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"X_features.csv\", index=False)\n",
    "Y.to_csv(\"Y_targets.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef17fa19",
   "metadata": {},
   "source": [
    "#### Split tr, tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "30e5dd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "# Choose: 70% training, 15% validation, 15% test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, Y, test_size=0.30, random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the split sets (tr/val/tt) to pickle files\n",
    "import pickle\n",
    "\n",
    "X_train.to_parquet(\"data/X_train.parquet\")\n",
    "X_val.to_parquet(\"data/X_val.parquet\")\n",
    "X_test.to_parquet(\"data/X_test.parquet\")\n",
    "\n",
    "y_train.to_parquet(\"data/y_train.parquet\")\n",
    "y_val.to_parquet(\"data/y_val.parquet\")\n",
    "y_test.to_parquet(\"data/y_test.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a3b1a6",
   "metadata": {},
   "source": [
    "#### Functions to integrate W&B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16a2e22",
   "metadata": {},
   "source": [
    "The functions are in file: train_xgb_sweep.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeac89f3",
   "metadata": {},
   "source": [
    "The sweep is performed directly from the Anaconda terminal. <br>\n",
    "Activate the right environment and go to the folder that contains the sweep.yaml file.<br>\n",
    "Run: <br>\n",
    "\">\"wandb sweep sweep_n.yaml <br>\n",
    "where n is the number of sweep. <br>\n",
    "Then, activate the agent with the sweep_id given in the previous step: <br>\n",
    ">wand agent <entity/project_name/sweep_id> <br>\n",
    "Example: <br>\n",
    ">wandb agent 100496657-universidad-carlos-iii-de-madrid/DS-HPE/s2xeaxuh <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fda408d",
   "metadata": {},
   "source": [
    "## Legacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb7189",
   "metadata": {},
   "source": [
    "#### Evaluate the best model over test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607708f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import X_train, y_train, X_val, y_val, X_test, y_test\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data\n",
    "X_train_full = pd.concat([X_train, X_val], axis=0)\n",
    "y_train_full = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "X_train_full_np = X_train_full.to_numpy()\n",
    "y_train_full_np = y_train_full.to_numpy()\n",
    "X_test_np = X_test.to_numpy()\n",
    "y_test_np = y_test.to_numpy()\n",
    "\n",
    "# Build model with chosen best hyperparameters\n",
    "best_model = MultiOutputRegressor(\n",
    "    xgb.XGBRegressor(\n",
    "        tree_method=\"hist\",\n",
    "        enable_categorical=True,\n",
    "        n_estimators=BEST_N_ESTIMATORS,\n",
    "        max_depth=BEST_MAX_DEPTH,\n",
    "        learning_rate=BEST_LR,\n",
    "        subsample=BEST_SUBSAMPLE,\n",
    "        colsample_bytree=BEST_COLSAMPLE,\n",
    "        min_child_weight=BEST_MIN_CHILD_WEIGHT,\n",
    "        random_state=42,\n",
    "    )\n",
    ")\n",
    "\n",
    "best_model.fit(X_train_full_np, y_train_full_np)\n",
    "\n",
    "# Final test evaluation\n",
    "metrics_test, y_pred_test = evaluate_model(best_model, X_test_np, y_test_np, model_type=\"sklearn\")\n",
    "print(metrics_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de9ae919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL RMSE: 2262.667\n",
      "VAL R²:   0.950\n",
      "TEST RMSE: 2044.847\n",
      "TEST R²:   0.957\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(model, X, y, name):\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    print(f\"{name} RMSE: {rmse:.3f}\")\n",
    "    print(f\"{name} R²:   {r2:.3f}\")\n",
    "\n",
    "evaluate(model, X_val, y_val, \"VAL\")\n",
    "evaluate(model, X_test, y_test, \"TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc5955",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c082e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FOR CLASSIC MODELS\n",
    "\n",
    "# Assuming you have your data in X (features) and y (labels)\n",
    "\"\"\"X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Fit only on train!\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "\"\"\"\n",
    "### FOR TORCH MODELS\n",
    "\n",
    "# Convert to tensors (on CPU)\n",
    "\"\"\"X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)  # Use float32 for regression\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create datasets and loaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "batch_size = 1028\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62a772fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches - Train: 68, Val: 79, Test: 79\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of batches - Train: {len(train_loader)}, Val: {len(val_loader)}, Test: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73d04a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./models/code_models/')\n",
    "\n",
    "import sklearn_models\n",
    "import torch_models\n",
    "import training_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fbedb8",
   "metadata": {},
   "source": [
    "## Legacy: unused code in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b006a97",
   "metadata": {},
   "source": [
    "### SKLEARN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78398ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: iqbalch (iqbalch-universidad-carlos-iii-de-madrid) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\iqbal\\Desktop\\4º Carrera\\Proyecto En DS\\DS-HPE\\wandb\\run-20251109_202412-hdb8iu3d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test/runs/hdb8iu3d' target=\"_blank\">RandomForest_Default</a></strong> to <a href='https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test/runs/hdb8iu3d' target=\"_blank\">https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test/runs/hdb8iu3d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForest_Default...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_mae_max_power</td><td>▁</td></tr><tr><td>train_mae_mean</td><td>▁</td></tr><tr><td>train_mae_mean_power</td><td>▁</td></tr><tr><td>train_mae_min_power</td><td>▁</td></tr><tr><td>train_r2_max_power</td><td>▁</td></tr><tr><td>train_r2_mean</td><td>▁</td></tr><tr><td>train_r2_mean_power</td><td>▁</td></tr><tr><td>train_r2_min_power</td><td>▁</td></tr><tr><td>train_rmse_max_power</td><td>▁</td></tr><tr><td>train_rmse_mean</td><td>▁</td></tr><tr><td>+14</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_val_mae</td><td>126.27648</td></tr><tr><td>best_val_r2</td><td>0.31887</td></tr><tr><td>best_val_rmse</td><td>180.87846</td></tr><tr><td>train_mae_max_power</td><td>123.25696</td></tr><tr><td>train_mae_mean</td><td>100.22107</td></tr><tr><td>train_mae_mean_power</td><td>91.2246</td></tr><tr><td>train_mae_min_power</td><td>86.18164</td></tr><tr><td>train_r2_max_power</td><td>0.56261</td></tr><tr><td>train_r2_mean</td><td>0.54462</td></tr><tr><td>train_r2_mean_power</td><td>0.51828</td></tr><tr><td>+17</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RandomForest_Default</strong> at: <a href='https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test/runs/hdb8iu3d' target=\"_blank\">https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test/runs/hdb8iu3d</a><br> View project at: <a href='https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251109_202412-hdb8iu3d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Metrics:\n",
      "val_rmse_mean_power: 161.7926\n",
      "val_mae_mean_power: 113.5575\n",
      "val_r2_mean_power: 0.3041\n",
      "val_rmse_min_power: 159.8107\n",
      "val_mae_min_power: 108.7766\n",
      "val_r2_min_power: 0.3294\n",
      "val_rmse_max_power: 221.0320\n",
      "val_mae_max_power: 156.4954\n",
      "val_r2_max_power: 0.3231\n",
      "val_rmse_mean: 180.8785\n",
      "val_mae_mean: 126.2765\n",
      "val_r2_mean: 0.3189\n",
      "\n",
      "Test Set Metrics:\n",
      "test_rmse_mean_power: 161.3757\n",
      "test_mae_mean_power: 113.4599\n",
      "test_r2_mean_power: 0.3050\n",
      "test_mape_mean_power: 15.8715\n",
      "test_rmse_min_power: 160.0210\n",
      "test_mae_min_power: 109.1074\n",
      "test_r2_min_power: 0.3190\n",
      "test_mape_min_power: 22.8296\n",
      "test_rmse_max_power: 221.0219\n",
      "test_mae_max_power: 156.7295\n",
      "test_r2_max_power: 0.3255\n",
      "test_mape_max_power: 19.9669\n",
      "test_rmse_mean: 180.8062\n",
      "test_mae_mean: 126.4323\n",
      "test_r2_mean: 0.3165\n",
      "test_mape_mean: 19.5560\n"
     ]
    }
   ],
   "source": [
    "rf_model = sklearn_models.get_random_forest()\n",
    "\n",
    "rf_trainer = training_utils.SklearnTrainer(\n",
    "    model=rf_model,\n",
    "    model_name=\"RandomForest_Default\",\n",
    "    project_name=\"Test\",\n",
    "    entity=\"iqbalch-universidad-carlos-iii-de-madrid\" \n",
    ")\n",
    "\n",
    "rf_model, rf_metrics = rf_trainer.train(\n",
    "    X_train_scaled, y_train,\n",
    "    X_val_scaled, y_val,\n",
    "    config= rf_model.get_params()\n",
    ")\n",
    "\n",
    "print(\"\\nValidation Metrics:\")\n",
    "for key, value in rf_metrics.items():\n",
    "    if 'val' in key:\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "test_metrics, test_predictions = training_utils.evaluate_model(\n",
    "    rf_model, X_test_scaled, y_test, model_type=\"sklearn\"\n",
    ")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "for key, value in test_metrics.items():\n",
    "    print(f\"{key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d78abd",
   "metadata": {},
   "source": [
    "### TORCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888677a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0f14247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\iqbal\\Desktop\\4º Carrera\\Proyecto En DS\\DS-HPE\\wandb\\run-20251109_204922-4hdlnfgm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test/runs/4hdlnfgm' target=\"_blank\">MLP Model</a></strong> to <a href='https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test/runs/4hdlnfgm' target=\"_blank\">https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test/runs/4hdlnfgm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iqbal\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 127\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>lr</td><td>██████████████████████████▄▄▃▃▃▃▃▃▃▂▂▂▂▁</td></tr><tr><td>train_loss</td><td>███▇▆▄▄▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_rmse</td><td>█▇▆▆▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mae_max_power</td><td>███▇▆▅▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mae_mean_power</td><td>██▇▇▇▆▅▄▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_mae_min_power</td><td>███▆▆▅▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_r2_max_power</td><td>▁▂▃▃▄▄▅▅▅▆▆▇▇▇██████████████████████████</td></tr><tr><td>val_r2_mean_power</td><td>▁▂▂▄▄▆▆▇▇▇██████████████████████████████</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>112</td></tr><tr><td>best_val_loss</td><td>45731.27255</td></tr><tr><td>best_val_rmse</td><td>213.84871</td></tr><tr><td>epoch</td><td>127</td></tr><tr><td>lr</td><td>3e-05</td></tr><tr><td>train_loss</td><td>47647.11437</td></tr><tr><td>train_rmse</td><td>218.28219</td></tr><tr><td>val_loss</td><td>46053.23353</td></tr><tr><td>val_mae_max_power</td><td>196.73834</td></tr><tr><td>val_mae_mean_power</td><td>140.24409</td></tr><tr><td>+8</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">MLP Model</strong> at: <a href='https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test/runs/4hdlnfgm' target=\"_blank\">https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test/runs/4hdlnfgm</a><br> View project at: <a href='https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test' target=\"_blank\">https://wandb.ai/iqbalch-universidad-carlos-iii-de-madrid/Test</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251109_204922-4hdlnfgm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Metrics:\n",
      "RMSE: 211.1253\n",
      "MAE: 156.9213\n",
      "R2: 0.0703\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_scaled.shape[1]\n",
    "siple_mlp_model = torch_models.SimpleMLP(input_dim=input_dim)\n",
    "\n",
    "resnet_trainer = training_utils.PyTorchTrainer(\n",
    "    model=siple_mlp_model,\n",
    "    model_name=\"MLP Model\",\n",
    "    project_name=\"Test\",\n",
    "    entity=\"iqbalch-universidad-carlos-iii-de-madrid\"\n",
    ")\n",
    "\n",
    "resnet_model, resnet_best_metrics = resnet_trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=150,\n",
    "    lr=0.001,\n",
    "    weight_decay=1e-5,\n",
    "    patience=15,\n",
    ")\n",
    "\n",
    "# Evaluate on test\n",
    "resnet_test_metrics, _ = training_utils.evaluate_model(\n",
    "    resnet_model, X_test_scaled, y_test, model_type=\"pytorch\"\n",
    ")\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"RMSE: {resnet_test_metrics['test_rmse_mean']:.4f}\")\n",
    "print(f\"MAE: {resnet_test_metrics['test_mae_mean']:.4f}\")\n",
    "print(f\"R2: {resnet_test_metrics['test_r2_mean']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e8981c",
   "metadata": {},
   "source": [
    "### Legacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ebca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "# data_path = r\"./data/interm/data_to_train_meantime.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1755d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THE ESSENTIALS\n",
    "\n",
    "# df = pd.read_csv(data_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsnp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
